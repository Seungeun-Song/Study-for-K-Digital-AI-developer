{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzlUoJjiJ59c"
      },
      "source": [
        "import seaborn as sns\r\n",
        "\r\n",
        "iris = sns.load_dataset('iris')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IXkU2BlKMsc",
        "outputId": "c62ab9a4-ab54-4407-8a9d-bb55cf6fb2dc"
      },
      "source": [
        "iris.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   species       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_IcHcpDKOZ-",
        "outputId": "da89aa12-546f-495e-d810-388028630576"
      },
      "source": [
        "iris.species.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "versicolor    50\n",
              "setosa        50\n",
              "virginica     50\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVHqUCV5KTQt",
        "outputId": "5fd41dcb-1c5a-479c-c41e-524074b58fb3"
      },
      "source": [
        "iris_AR = iris.values\r\n",
        "iris_AR"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2, 'setosa'],\n",
              "       [4.9, 3.0, 1.4, 0.2, 'setosa'],\n",
              "       [4.7, 3.2, 1.3, 0.2, 'setosa'],\n",
              "       [4.6, 3.1, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.6, 1.4, 0.2, 'setosa'],\n",
              "       [5.4, 3.9, 1.7, 0.4, 'setosa'],\n",
              "       [4.6, 3.4, 1.4, 0.3, 'setosa'],\n",
              "       [5.0, 3.4, 1.5, 0.2, 'setosa'],\n",
              "       [4.4, 2.9, 1.4, 0.2, 'setosa'],\n",
              "       [4.9, 3.1, 1.5, 0.1, 'setosa'],\n",
              "       [5.4, 3.7, 1.5, 0.2, 'setosa'],\n",
              "       [4.8, 3.4, 1.6, 0.2, 'setosa'],\n",
              "       [4.8, 3.0, 1.4, 0.1, 'setosa'],\n",
              "       [4.3, 3.0, 1.1, 0.1, 'setosa'],\n",
              "       [5.8, 4.0, 1.2, 0.2, 'setosa'],\n",
              "       [5.7, 4.4, 1.5, 0.4, 'setosa'],\n",
              "       [5.4, 3.9, 1.3, 0.4, 'setosa'],\n",
              "       [5.1, 3.5, 1.4, 0.3, 'setosa'],\n",
              "       [5.7, 3.8, 1.7, 0.3, 'setosa'],\n",
              "       [5.1, 3.8, 1.5, 0.3, 'setosa'],\n",
              "       [5.4, 3.4, 1.7, 0.2, 'setosa'],\n",
              "       [5.1, 3.7, 1.5, 0.4, 'setosa'],\n",
              "       [4.6, 3.6, 1.0, 0.2, 'setosa'],\n",
              "       [5.1, 3.3, 1.7, 0.5, 'setosa'],\n",
              "       [4.8, 3.4, 1.9, 0.2, 'setosa'],\n",
              "       [5.0, 3.0, 1.6, 0.2, 'setosa'],\n",
              "       [5.0, 3.4, 1.6, 0.4, 'setosa'],\n",
              "       [5.2, 3.5, 1.5, 0.2, 'setosa'],\n",
              "       [5.2, 3.4, 1.4, 0.2, 'setosa'],\n",
              "       [4.7, 3.2, 1.6, 0.2, 'setosa'],\n",
              "       [4.8, 3.1, 1.6, 0.2, 'setosa'],\n",
              "       [5.4, 3.4, 1.5, 0.4, 'setosa'],\n",
              "       [5.2, 4.1, 1.5, 0.1, 'setosa'],\n",
              "       [5.5, 4.2, 1.4, 0.2, 'setosa'],\n",
              "       [4.9, 3.1, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.2, 1.2, 0.2, 'setosa'],\n",
              "       [5.5, 3.5, 1.3, 0.2, 'setosa'],\n",
              "       [4.9, 3.6, 1.4, 0.1, 'setosa'],\n",
              "       [4.4, 3.0, 1.3, 0.2, 'setosa'],\n",
              "       [5.1, 3.4, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.5, 1.3, 0.3, 'setosa'],\n",
              "       [4.5, 2.3, 1.3, 0.3, 'setosa'],\n",
              "       [4.4, 3.2, 1.3, 0.2, 'setosa'],\n",
              "       [5.0, 3.5, 1.6, 0.6, 'setosa'],\n",
              "       [5.1, 3.8, 1.9, 0.4, 'setosa'],\n",
              "       [4.8, 3.0, 1.4, 0.3, 'setosa'],\n",
              "       [5.1, 3.8, 1.6, 0.2, 'setosa'],\n",
              "       [4.6, 3.2, 1.4, 0.2, 'setosa'],\n",
              "       [5.3, 3.7, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.3, 1.4, 0.2, 'setosa'],\n",
              "       [7.0, 3.2, 4.7, 1.4, 'versicolor'],\n",
              "       [6.4, 3.2, 4.5, 1.5, 'versicolor'],\n",
              "       [6.9, 3.1, 4.9, 1.5, 'versicolor'],\n",
              "       [5.5, 2.3, 4.0, 1.3, 'versicolor'],\n",
              "       [6.5, 2.8, 4.6, 1.5, 'versicolor'],\n",
              "       [5.7, 2.8, 4.5, 1.3, 'versicolor'],\n",
              "       [6.3, 3.3, 4.7, 1.6, 'versicolor'],\n",
              "       [4.9, 2.4, 3.3, 1.0, 'versicolor'],\n",
              "       [6.6, 2.9, 4.6, 1.3, 'versicolor'],\n",
              "       [5.2, 2.7, 3.9, 1.4, 'versicolor'],\n",
              "       [5.0, 2.0, 3.5, 1.0, 'versicolor'],\n",
              "       [5.9, 3.0, 4.2, 1.5, 'versicolor'],\n",
              "       [6.0, 2.2, 4.0, 1.0, 'versicolor'],\n",
              "       [6.1, 2.9, 4.7, 1.4, 'versicolor'],\n",
              "       [5.6, 2.9, 3.6, 1.3, 'versicolor'],\n",
              "       [6.7, 3.1, 4.4, 1.4, 'versicolor'],\n",
              "       [5.6, 3.0, 4.5, 1.5, 'versicolor'],\n",
              "       [5.8, 2.7, 4.1, 1.0, 'versicolor'],\n",
              "       [6.2, 2.2, 4.5, 1.5, 'versicolor'],\n",
              "       [5.6, 2.5, 3.9, 1.1, 'versicolor'],\n",
              "       [5.9, 3.2, 4.8, 1.8, 'versicolor'],\n",
              "       [6.1, 2.8, 4.0, 1.3, 'versicolor'],\n",
              "       [6.3, 2.5, 4.9, 1.5, 'versicolor'],\n",
              "       [6.1, 2.8, 4.7, 1.2, 'versicolor'],\n",
              "       [6.4, 2.9, 4.3, 1.3, 'versicolor'],\n",
              "       [6.6, 3.0, 4.4, 1.4, 'versicolor'],\n",
              "       [6.8, 2.8, 4.8, 1.4, 'versicolor'],\n",
              "       [6.7, 3.0, 5.0, 1.7, 'versicolor'],\n",
              "       [6.0, 2.9, 4.5, 1.5, 'versicolor'],\n",
              "       [5.7, 2.6, 3.5, 1.0, 'versicolor'],\n",
              "       [5.5, 2.4, 3.8, 1.1, 'versicolor'],\n",
              "       [5.5, 2.4, 3.7, 1.0, 'versicolor'],\n",
              "       [5.8, 2.7, 3.9, 1.2, 'versicolor'],\n",
              "       [6.0, 2.7, 5.1, 1.6, 'versicolor'],\n",
              "       [5.4, 3.0, 4.5, 1.5, 'versicolor'],\n",
              "       [6.0, 3.4, 4.5, 1.6, 'versicolor'],\n",
              "       [6.7, 3.1, 4.7, 1.5, 'versicolor'],\n",
              "       [6.3, 2.3, 4.4, 1.3, 'versicolor'],\n",
              "       [5.6, 3.0, 4.1, 1.3, 'versicolor'],\n",
              "       [5.5, 2.5, 4.0, 1.3, 'versicolor'],\n",
              "       [5.5, 2.6, 4.4, 1.2, 'versicolor'],\n",
              "       [6.1, 3.0, 4.6, 1.4, 'versicolor'],\n",
              "       [5.8, 2.6, 4.0, 1.2, 'versicolor'],\n",
              "       [5.0, 2.3, 3.3, 1.0, 'versicolor'],\n",
              "       [5.6, 2.7, 4.2, 1.3, 'versicolor'],\n",
              "       [5.7, 3.0, 4.2, 1.2, 'versicolor'],\n",
              "       [5.7, 2.9, 4.2, 1.3, 'versicolor'],\n",
              "       [6.2, 2.9, 4.3, 1.3, 'versicolor'],\n",
              "       [5.1, 2.5, 3.0, 1.1, 'versicolor'],\n",
              "       [5.7, 2.8, 4.1, 1.3, 'versicolor'],\n",
              "       [6.3, 3.3, 6.0, 2.5, 'virginica'],\n",
              "       [5.8, 2.7, 5.1, 1.9, 'virginica'],\n",
              "       [7.1, 3.0, 5.9, 2.1, 'virginica'],\n",
              "       [6.3, 2.9, 5.6, 1.8, 'virginica'],\n",
              "       [6.5, 3.0, 5.8, 2.2, 'virginica'],\n",
              "       [7.6, 3.0, 6.6, 2.1, 'virginica'],\n",
              "       [4.9, 2.5, 4.5, 1.7, 'virginica'],\n",
              "       [7.3, 2.9, 6.3, 1.8, 'virginica'],\n",
              "       [6.7, 2.5, 5.8, 1.8, 'virginica'],\n",
              "       [7.2, 3.6, 6.1, 2.5, 'virginica'],\n",
              "       [6.5, 3.2, 5.1, 2.0, 'virginica'],\n",
              "       [6.4, 2.7, 5.3, 1.9, 'virginica'],\n",
              "       [6.8, 3.0, 5.5, 2.1, 'virginica'],\n",
              "       [5.7, 2.5, 5.0, 2.0, 'virginica'],\n",
              "       [5.8, 2.8, 5.1, 2.4, 'virginica'],\n",
              "       [6.4, 3.2, 5.3, 2.3, 'virginica'],\n",
              "       [6.5, 3.0, 5.5, 1.8, 'virginica'],\n",
              "       [7.7, 3.8, 6.7, 2.2, 'virginica'],\n",
              "       [7.7, 2.6, 6.9, 2.3, 'virginica'],\n",
              "       [6.0, 2.2, 5.0, 1.5, 'virginica'],\n",
              "       [6.9, 3.2, 5.7, 2.3, 'virginica'],\n",
              "       [5.6, 2.8, 4.9, 2.0, 'virginica'],\n",
              "       [7.7, 2.8, 6.7, 2.0, 'virginica'],\n",
              "       [6.3, 2.7, 4.9, 1.8, 'virginica'],\n",
              "       [6.7, 3.3, 5.7, 2.1, 'virginica'],\n",
              "       [7.2, 3.2, 6.0, 1.8, 'virginica'],\n",
              "       [6.2, 2.8, 4.8, 1.8, 'virginica'],\n",
              "       [6.1, 3.0, 4.9, 1.8, 'virginica'],\n",
              "       [6.4, 2.8, 5.6, 2.1, 'virginica'],\n",
              "       [7.2, 3.0, 5.8, 1.6, 'virginica'],\n",
              "       [7.4, 2.8, 6.1, 1.9, 'virginica'],\n",
              "       [7.9, 3.8, 6.4, 2.0, 'virginica'],\n",
              "       [6.4, 2.8, 5.6, 2.2, 'virginica'],\n",
              "       [6.3, 2.8, 5.1, 1.5, 'virginica'],\n",
              "       [6.1, 2.6, 5.6, 1.4, 'virginica'],\n",
              "       [7.7, 3.0, 6.1, 2.3, 'virginica'],\n",
              "       [6.3, 3.4, 5.6, 2.4, 'virginica'],\n",
              "       [6.4, 3.1, 5.5, 1.8, 'virginica'],\n",
              "       [6.0, 3.0, 4.8, 1.8, 'virginica'],\n",
              "       [6.9, 3.1, 5.4, 2.1, 'virginica'],\n",
              "       [6.7, 3.1, 5.6, 2.4, 'virginica'],\n",
              "       [6.9, 3.1, 5.1, 2.3, 'virginica'],\n",
              "       [5.8, 2.7, 5.1, 1.9, 'virginica'],\n",
              "       [6.8, 3.2, 5.9, 2.3, 'virginica'],\n",
              "       [6.7, 3.3, 5.7, 2.5, 'virginica'],\n",
              "       [6.7, 3.0, 5.2, 2.3, 'virginica'],\n",
              "       [6.3, 2.5, 5.0, 1.9, 'virginica'],\n",
              "       [6.5, 3.0, 5.2, 2.0, 'virginica'],\n",
              "       [6.2, 3.4, 5.4, 2.3, 'virginica'],\n",
              "       [5.9, 3.0, 5.1, 1.8, 'virginica']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBAi1K3gKY3l",
        "outputId": "2cbc5baa-86cb-4455-fdc2-879bdaa81aa9"
      },
      "source": [
        "AR_X = iris_AR[:,:4].astype(float)\r\n",
        "AR_y = iris_AR[:,4]\r\n",
        "\r\n",
        "AR_X.shape, AR_y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaKyLjneKmGO",
        "outputId": "b0b6e5ca-6399-4db4-c33d-7c2c1829dee0"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "encoder = LabelEncoder()\r\n",
        "AR_yLBE = encoder.fit_transform(AR_y)\r\n",
        "\r\n",
        "AR_yLBE\r\n",
        "                                "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcYUratLLVqM",
        "outputId": "07dd7ce6-c015-45dc-b47c-201dc961da70"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "AR_yOHE = tf.keras.utils.to_categorical(AR_yLBE)\r\n",
        "AR_yOHE[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2orHgtzgLmuL",
        "outputId": "469277c3-5c66-4613-9b8c-f2b0bd8b6456"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(AR_X, AR_yOHE, test_size = 0.3, random_state=2045)\r\n",
        "\r\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((105, 4), (45, 4), (105, 3), (45, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akZONy0XMXS0"
      },
      "source": [
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfP3VSOEMe7j"
      },
      "source": [
        "Model_iris = models.Sequential()\r\n",
        "\r\n",
        "Model_iris.add(layers.Dense(6, activation='tanh', input_shape=(4,)))\r\n",
        "#Model_iris.add(layers.Dense(8, activation='tanh'))\r\n",
        "Model_iris.add(layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3C9GWcxNjRL",
        "outputId": "70f72620-6540-4cc6-b324-47afaa064370"
      },
      "source": [
        "Model_iris.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 6)                 30        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 21        \n",
            "=================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "KGvhGFTLNl0D",
        "outputId": "aa90155a-c9a1-4d21-ce3a-7429dd1881de"
      },
      "source": [
        "from tensorflow.keras import utils\r\n",
        "utils.plot_model(Model_iris)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdFx_GdeNr28"
      },
      "source": [
        "Model_iris.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['Accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKIE5GYGN2lb",
        "outputId": "378d5e07-f292-4f63-beed-9bdd8cefeb15"
      },
      "source": [
        "History=Model_iris.fit(X_train, y_train,\r\n",
        "                       epochs = 500,\r\n",
        "                       batch_size=7,\r\n",
        "                       validation_data=(X_test, y_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 15ms/step - loss: 1.2637 - accuracy: 0.0000e+00 - val_loss: 1.2424 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1748 - accuracy: 0.0000e+00 - val_loss: 1.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0430 - accuracy: 0.0000e+00 - val_loss: 1.0699 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0054 - accuracy: 0.0000e+00 - val_loss: 0.9973 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9531 - accuracy: 0.0000e+00 - val_loss: 0.9369 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9126 - accuracy: 0.0000e+00 - val_loss: 0.8887 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8924 - accuracy: 0.0000e+00 - val_loss: 0.8498 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8585 - accuracy: 0.0000e+00 - val_loss: 0.8158 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8191 - accuracy: 0.0000e+00 - val_loss: 0.7889 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7833 - accuracy: 0.0000e+00 - val_loss: 0.7640 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7814 - accuracy: 0.0000e+00 - val_loss: 0.7448 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7705 - accuracy: 0.0000e+00 - val_loss: 0.7281 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7339 - accuracy: 0.0000e+00 - val_loss: 0.7103 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7223 - accuracy: 0.0000e+00 - val_loss: 0.6935 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7222 - accuracy: 0.0000e+00 - val_loss: 0.6781 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.0000e+00 - val_loss: 0.6623 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7119 - accuracy: 0.0000e+00 - val_loss: 0.6482 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.0000e+00 - val_loss: 0.6359 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.0000e+00 - val_loss: 0.6239 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6590 - accuracy: 0.0000e+00 - val_loss: 0.6132 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.0000e+00 - val_loss: 0.6038 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.0000e+00 - val_loss: 0.5943 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.0000e+00 - val_loss: 0.5857 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.0000e+00 - val_loss: 0.5778 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.0000e+00 - val_loss: 0.5704 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.5604 - accuracy: 0.0000e+00 - val_loss: 0.5630 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.0000e+00 - val_loss: 0.5561 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.0000e+00 - val_loss: 0.5497 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.0000e+00 - val_loss: 0.5435 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.0000e+00 - val_loss: 0.5378 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.0000e+00 - val_loss: 0.5320 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.0000e+00 - val_loss: 0.5262 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.0000e+00 - val_loss: 0.5210 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.0000e+00 - val_loss: 0.5159 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.0000e+00 - val_loss: 0.5105 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.0000e+00 - val_loss: 0.5059 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.0000e+00 - val_loss: 0.5005 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.0000e+00 - val_loss: 0.4961 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.0000e+00 - val_loss: 0.4915 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.0000e+00 - val_loss: 0.4871 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.0000e+00 - val_loss: 0.4827 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.0000e+00 - val_loss: 0.4781 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.0000e+00 - val_loss: 0.4739 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.0000e+00 - val_loss: 0.4698 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.0000e+00 - val_loss: 0.4657 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.0000e+00 - val_loss: 0.4614 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.0000e+00 - val_loss: 0.4574 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.0000e+00 - val_loss: 0.4534 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.0000e+00 - val_loss: 0.4495 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.0000e+00 - val_loss: 0.4457 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.0000e+00 - val_loss: 0.4420 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.0000e+00 - val_loss: 0.4380 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.0000e+00 - val_loss: 0.4342 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.0000e+00 - val_loss: 0.4306 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.0000e+00 - val_loss: 0.4268 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.0000e+00 - val_loss: 0.4233 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.0000e+00 - val_loss: 0.4196 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.0000e+00 - val_loss: 0.4160 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.0000e+00 - val_loss: 0.4127 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.0000e+00 - val_loss: 0.4095 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.0000e+00 - val_loss: 0.4055 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.0000e+00 - val_loss: 0.4021 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.0000e+00 - val_loss: 0.3987 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.0000e+00 - val_loss: 0.3954 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.0000e+00 - val_loss: 0.3918 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.0000e+00 - val_loss: 0.3885 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.0000e+00 - val_loss: 0.3851 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.0000e+00 - val_loss: 0.3817 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.0000e+00 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.0000e+00 - val_loss: 0.3751 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.0000e+00 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.0000e+00 - val_loss: 0.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.0000e+00 - val_loss: 0.3657 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.0000e+00 - val_loss: 0.3621 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.0000e+00 - val_loss: 0.3591 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.0000e+00 - val_loss: 0.3464 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.0000e+00 - val_loss: 0.3432 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.0000e+00 - val_loss: 0.3400 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.0000e+00 - val_loss: 0.3371 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.0000e+00 - val_loss: 0.3339 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.0000e+00 - val_loss: 0.3309 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.0000e+00 - val_loss: 0.3278 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.0000e+00 - val_loss: 0.3248 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.3219 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.0000e+00 - val_loss: 0.3192 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.0000e+00 - val_loss: 0.3158 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.0000e+00 - val_loss: 0.3128 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.0000e+00 - val_loss: 0.3099 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.0000e+00 - val_loss: 0.3072 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.0000e+00 - val_loss: 0.3043 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3015 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.0000e+00 - val_loss: 0.2985 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.0000e+00 - val_loss: 0.2961 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.0000e+00 - val_loss: 0.2931 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.0000e+00 - val_loss: 0.2902 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.0000e+00 - val_loss: 0.2873 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.0000e+00 - val_loss: 0.2849 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.0000e+00 - val_loss: 0.2821 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.2794 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.2768 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.0000e+00 - val_loss: 0.2740 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.0000e+00 - val_loss: 0.2714 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.0000e+00 - val_loss: 0.2691 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.2662 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.0000e+00 - val_loss: 0.2637 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.0000e+00 - val_loss: 0.2614 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.0000e+00 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.0000e+00 - val_loss: 0.2562 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.0000e+00 - val_loss: 0.2538 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.0000e+00 - val_loss: 0.2515 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2796 - accuracy: 0.0000e+00 - val_loss: 0.2489 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.0000e+00 - val_loss: 0.2465 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.0000e+00 - val_loss: 0.2441 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.0000e+00 - val_loss: 0.2425 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.0000e+00 - val_loss: 0.2395 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.0000e+00 - val_loss: 0.2372 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.0000e+00 - val_loss: 0.2350 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2759 - accuracy: 0.0000e+00 - val_loss: 0.2308 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.0000e+00 - val_loss: 0.2288 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.0000e+00 - val_loss: 0.2278 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.0000e+00 - val_loss: 0.2239 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.0000e+00 - val_loss: 0.2222 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2329 - accuracy: 0.0000e+00 - val_loss: 0.2198 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2389 - accuracy: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2704 - accuracy: 0.0000e+00 - val_loss: 0.2156 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.0000e+00 - val_loss: 0.2151 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.0000e+00 - val_loss: 0.2115 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.0000e+00 - val_loss: 0.2094 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.0000e+00 - val_loss: 0.2079 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2292 - accuracy: 0.0000e+00 - val_loss: 0.2058 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.0000e+00 - val_loss: 0.2016 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.0000e+00 - val_loss: 0.2004 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.0000e+00 - val_loss: 0.1988 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2647 - accuracy: 0.0000e+00 - val_loss: 0.1964 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2277 - accuracy: 0.0000e+00 - val_loss: 0.1955 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.0000e+00 - val_loss: 0.1925 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.0000e+00 - val_loss: 0.1909 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.0000e+00 - val_loss: 0.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.0000e+00 - val_loss: 0.1884 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.0000e+00 - val_loss: 0.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2084 - accuracy: 0.0000e+00 - val_loss: 0.1844 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2225 - accuracy: 0.0000e+00 - val_loss: 0.1830 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.0000e+00 - val_loss: 0.1806 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.0000e+00 - val_loss: 0.1787 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.0000e+00 - val_loss: 0.1787 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2018 - accuracy: 0.0000e+00 - val_loss: 0.1757 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2287 - accuracy: 0.0000e+00 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.0000e+00 - val_loss: 0.1727 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.0000e+00 - val_loss: 0.1707 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.0000e+00 - val_loss: 0.1694 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.0000e+00 - val_loss: 0.1680 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.0000e+00 - val_loss: 0.1671 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.0000e+00 - val_loss: 0.1649 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.0000e+00 - val_loss: 0.1636 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2014 - accuracy: 0.0000e+00 - val_loss: 0.1640 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.0000e+00 - val_loss: 0.1603 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.0000e+00 - val_loss: 0.1592 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 0.0000e+00 - val_loss: 0.1588 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1883 - accuracy: 0.0000e+00 - val_loss: 0.1568 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1798 - accuracy: 0.0000e+00 - val_loss: 0.1547 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.0000e+00 - val_loss: 0.1536 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.0000e+00 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.0000e+00 - val_loss: 0.1524 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.0000e+00 - val_loss: 0.1503 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.0000e+00 - val_loss: 0.1482 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.0000e+00 - val_loss: 0.1474 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.0000e+00 - val_loss: 0.1363 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1349 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.0000e+00 - val_loss: 0.1329 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1627 - accuracy: 0.0000e+00 - val_loss: 0.1322 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.0000e+00 - val_loss: 0.1345 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1592 - accuracy: 0.0000e+00 - val_loss: 0.1298 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1287 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1290 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1796 - accuracy: 0.0000e+00 - val_loss: 0.1272 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1255 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.0000e+00 - val_loss: 0.1287 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1685 - accuracy: 0.0000e+00 - val_loss: 0.1252 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1740 - accuracy: 0.0000e+00 - val_loss: 0.1235 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.0000e+00 - val_loss: 0.1216 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1594 - accuracy: 0.0000e+00 - val_loss: 0.1231 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1563 - accuracy: 0.0000e+00 - val_loss: 0.1201 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.0000e+00 - val_loss: 0.1205 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1188 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1190 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.0000e+00 - val_loss: 0.1161 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1163 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.0000e+00 - val_loss: 0.1157 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1803 - accuracy: 0.0000e+00 - val_loss: 0.1140 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1149 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.0000e+00 - val_loss: 0.1148 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.0000e+00 - val_loss: 0.1110 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.0000e+00 - val_loss: 0.1103 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1130 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1097 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.0000e+00 - val_loss: 0.1084 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1088 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1075 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.0000e+00 - val_loss: 0.1071 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.0000e+00 - val_loss: 0.1052 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1050 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1061 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1025 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.0000e+00 - val_loss: 0.1026 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.0000e+00 - val_loss: 0.1020 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1541 - accuracy: 0.0000e+00 - val_loss: 0.1015 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.0000e+00 - val_loss: 0.1011 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.0000e+00 - val_loss: 0.1005 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.0000e+00 - val_loss: 0.0995 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.0980 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.0000e+00 - val_loss: 0.0984 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1318 - accuracy: 0.0000e+00 - val_loss: 0.0977 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.0000e+00 - val_loss: 0.0958 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.0000e+00 - val_loss: 0.0963 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.0983 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.0000e+00 - val_loss: 0.0963 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.0000e+00 - val_loss: 0.0934 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.0966 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - val_loss: 0.0923 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.0926 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.0000e+00 - val_loss: 0.0924 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.0923 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.0000e+00 - val_loss: 0.0903 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.0000e+00 - val_loss: 0.0889 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1601 - accuracy: 0.0000e+00 - val_loss: 0.0907 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.0000e+00 - val_loss: 0.0934 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.0000e+00 - val_loss: 0.0868 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.0000e+00 - val_loss: 0.0890 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.0000e+00 - val_loss: 0.0857 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.0930 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.0000e+00 - val_loss: 0.0861 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.0000e+00 - val_loss: 0.0856 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.0000e+00 - val_loss: 0.0851 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.0000e+00 - val_loss: 0.0850 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.0000e+00 - val_loss: 0.0860 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.0000e+00 - val_loss: 0.0836 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.0000e+00 - val_loss: 0.0857 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1222 - accuracy: 0.0000e+00 - val_loss: 0.0833 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.0000e+00 - val_loss: 0.0834 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1256 - accuracy: 0.0000e+00 - val_loss: 0.0808 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.0000e+00 - val_loss: 0.0821 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.0000e+00 - val_loss: 0.0840 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.0000e+00 - val_loss: 0.0797 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.0000e+00 - val_loss: 0.0801 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.0000e+00 - val_loss: 0.0835 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.0000e+00 - val_loss: 0.0792 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1235 - accuracy: 0.0000e+00 - val_loss: 0.0782 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.0794 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.0000e+00 - val_loss: 0.0797 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.0000e+00 - val_loss: 0.0761 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.0000e+00 - val_loss: 0.0778 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.0000e+00 - val_loss: 0.0788 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1244 - accuracy: 0.0000e+00 - val_loss: 0.0796 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.0000e+00 - val_loss: 0.0758 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.0000e+00 - val_loss: 0.0757 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.0000e+00 - val_loss: 0.0747 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.0000e+00 - val_loss: 0.0772 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.0000e+00 - val_loss: 0.0746 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.0000e+00 - val_loss: 0.0749 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.0000e+00 - val_loss: 0.0734 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.0000e+00 - val_loss: 0.0771 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.0000e+00 - val_loss: 0.0723 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.0000e+00 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1048 - accuracy: 0.0000e+00 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.0000e+00 - val_loss: 0.0728 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0000e+00 - val_loss: 0.0719 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.0000e+00 - val_loss: 0.0725 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.0000e+00 - val_loss: 0.0732 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.0000e+00 - val_loss: 0.0707 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.0000e+00 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.0000e+00 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0000e+00 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.0000e+00 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.0000e+00 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.0000e+00 - val_loss: 0.0719 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 0.0000e+00 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0000e+00 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.0000e+00 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.0000e+00 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.0000e+00 - val_loss: 0.0656 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.0000e+00 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.0000e+00 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.0000e+00 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.0000e+00 - val_loss: 0.0664 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.0000e+00 - val_loss: 0.0658 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.0000e+00 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.0000e+00 - val_loss: 0.0644 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.0000e+00 - val_loss: 0.0643 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.0000e+00 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.0000e+00 - val_loss: 0.0637 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.0000e+00 - val_loss: 0.0613 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.0000e+00 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.0000e+00 - val_loss: 0.0639 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.0000e+00 - val_loss: 0.0602 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.0000e+00 - val_loss: 0.0644 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.0000e+00 - val_loss: 0.0623 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.0000e+00 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.0000e+00 - val_loss: 0.0587 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.0000e+00 - val_loss: 0.0626 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.0000e+00 - val_loss: 0.0640 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.0000e+00 - val_loss: 0.0615 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.0000e+00 - val_loss: 0.0617 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.0000e+00 - val_loss: 0.0641 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.0000e+00 - val_loss: 0.0653 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.0000e+00 - val_loss: 0.0593 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.0000e+00 - val_loss: 0.0601 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.0000e+00 - val_loss: 0.0602 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.0000e+00 - val_loss: 0.0628 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.0000e+00 - val_loss: 0.0590 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.0000e+00 - val_loss: 0.0617 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.0000e+00 - val_loss: 0.0588 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.0000e+00 - val_loss: 0.0594 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.0000e+00 - val_loss: 0.0648 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.0000e+00 - val_loss: 0.0540 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.0000e+00 - val_loss: 0.0603 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.0000e+00 - val_loss: 0.0614 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.0000e+00 - val_loss: 0.0620 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.0000e+00 - val_loss: 0.0549 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0000e+00 - val_loss: 0.0596 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0000e+00 - val_loss: 0.0583 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.0000e+00 - val_loss: 0.0601 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.0000e+00 - val_loss: 0.0558 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.0000e+00 - val_loss: 0.0558 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.0000e+00 - val_loss: 0.0564 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.0000e+00 - val_loss: 0.0586 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.0000e+00 - val_loss: 0.0567 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.0000e+00 - val_loss: 0.0527 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0901 - accuracy: 0.0000e+00 - val_loss: 0.0620 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.0000e+00 - val_loss: 0.0584 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.0000e+00 - val_loss: 0.0527 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.0000e+00 - val_loss: 0.0594 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0000e+00 - val_loss: 0.0581 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.0000e+00 - val_loss: 0.0557 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0000e+00 - val_loss: 0.0567 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.0000e+00 - val_loss: 0.0563 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.0000e+00 - val_loss: 0.0555 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.0000e+00 - val_loss: 0.0524 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.0000e+00 - val_loss: 0.0569 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.0000e+00 - val_loss: 0.0519 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0000e+00 - val_loss: 0.0545 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.0000e+00 - val_loss: 0.0547 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0000e+00 - val_loss: 0.0532 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.0000e+00 - val_loss: 0.0576 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0000e+00 - val_loss: 0.0529 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.0000e+00 - val_loss: 0.0569 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.0000e+00 - val_loss: 0.0518 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0000e+00 - val_loss: 0.0516 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.0000e+00 - val_loss: 0.0562 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.0000e+00 - val_loss: 0.0559 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.0000e+00 - val_loss: 0.0496 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.0000e+00 - val_loss: 0.0534 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.0000e+00 - val_loss: 0.0510 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.0000e+00 - val_loss: 0.0522 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.0000e+00 - val_loss: 0.0557 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0000e+00 - val_loss: 0.0507 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0000e+00 - val_loss: 0.0508 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.0000e+00 - val_loss: 0.0539 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.0000e+00 - val_loss: 0.0501 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.0000e+00 - val_loss: 0.0499 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.0000e+00 - val_loss: 0.0532 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0000e+00 - val_loss: 0.0515 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.0000e+00 - val_loss: 0.0509 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0000e+00 - val_loss: 0.0511 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.0000e+00 - val_loss: 0.0508 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0000e+00 - val_loss: 0.0508 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.0000e+00 - val_loss: 0.0490 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.0000e+00 - val_loss: 0.0516 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.0000e+00 - val_loss: 0.0528 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.0000e+00 - val_loss: 0.0517 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.0000e+00 - val_loss: 0.0502 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0000e+00 - val_loss: 0.0500 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.0000e+00 - val_loss: 0.0505 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.0000e+00 - val_loss: 0.0516 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.0000e+00 - val_loss: 0.0492 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0000e+00 - val_loss: 0.0544 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.0000e+00 - val_loss: 0.0466 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.0000e+00 - val_loss: 0.0491 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.0000e+00 - val_loss: 0.0514 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.0000e+00 - val_loss: 0.0491 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0000e+00 - val_loss: 0.0470 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.0000e+00 - val_loss: 0.0539 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.0000e+00 - val_loss: 0.0473 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.0000e+00 - val_loss: 0.0497 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.0000e+00 - val_loss: 0.0457 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.0000e+00 - val_loss: 0.0522 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0000e+00 - val_loss: 0.0543 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0000e+00 - val_loss: 0.0488 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.0000e+00 - val_loss: 0.0460 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.0000e+00 - val_loss: 0.0502 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.0000e+00 - val_loss: 0.0468 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.0000e+00 - val_loss: 0.0465 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.0000e+00 - val_loss: 0.0466 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.0000e+00 - val_loss: 0.0486 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.0000e+00 - val_loss: 0.0475 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.0000e+00 - val_loss: 0.0521 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0000e+00 - val_loss: 0.0472 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.0000e+00 - val_loss: 0.0473 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.0000e+00 - val_loss: 0.0500 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.0000e+00 - val_loss: 0.0463 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.0000e+00 - val_loss: 0.0493 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.0000e+00 - val_loss: 0.0467 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.0000e+00 - val_loss: 0.0513 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0000e+00 - val_loss: 0.0528 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.0000e+00 - val_loss: 0.0403 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.0000e+00 - val_loss: 0.0501 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.0000e+00 - val_loss: 0.0443 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.0000e+00 - val_loss: 0.0474 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0000e+00 - val_loss: 0.0471 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.0000e+00 - val_loss: 0.0481 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.0000e+00 - val_loss: 0.0517 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.0000e+00 - val_loss: 0.0454 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.0000e+00 - val_loss: 0.0454 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.0000e+00 - val_loss: 0.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.0000e+00 - val_loss: 0.0427 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.0000e+00 - val_loss: 0.0489 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.0000e+00 - val_loss: 0.0510 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0000e+00 - val_loss: 0.0407 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.0000e+00 - val_loss: 0.0490 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.0000e+00 - val_loss: 0.0465 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.0000e+00 - val_loss: 0.0439 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.0000e+00 - val_loss: 0.0504 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0000e+00 - val_loss: 0.0460 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0000e+00 - val_loss: 0.0464 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.0000e+00 - val_loss: 0.0433 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0000e+00 - val_loss: 0.0444 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.0000e+00 - val_loss: 0.0453 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.0000e+00 - val_loss: 0.0460 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.0000e+00 - val_loss: 0.0468 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.0000e+00 - val_loss: 0.0463 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0000e+00 - val_loss: 0.0473 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0000e+00 - val_loss: 0.0480 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.0000e+00 - val_loss: 0.0473 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.0000e+00 - val_loss: 0.0444 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0000e+00 - val_loss: 0.0459 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.0000e+00 - val_loss: 0.0459 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.0000e+00 - val_loss: 0.0453 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.0427 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.0000e+00 - val_loss: 0.0462 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.0000e+00 - val_loss: 0.0496 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.0000e+00 - val_loss: 0.0446 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.0000e+00 - val_loss: 0.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.0000e+00 - val_loss: 0.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.0000e+00 - val_loss: 0.0458 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.0000e+00 - val_loss: 0.0447 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0000e+00 - val_loss: 0.0435 - val_accuracy: 0.0000e+00\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.0000e+00 - val_loss: 0.0416 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.0000e+00 - val_loss: 0.0435 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0000e+00 - val_loss: 0.0502 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.0000e+00 - val_loss: 0.0441 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.0000e+00 - val_loss: 0.0452 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.0000e+00 - val_loss: 0.0424 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.0000e+00 - val_loss: 0.0460 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.0000e+00 - val_loss: 0.0463 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.0000e+00 - val_loss: 0.0407 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.0000e+00 - val_loss: 0.0450 - val_accuracy: 0.0000e+00\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.0000e+00 - val_loss: 0.0473 - val_accuracy: 0.0000e+00\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.0000e+00 - val_loss: 0.0445 - val_accuracy: 0.0000e+00\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.0421 - val_accuracy: 0.0000e+00\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.0000e+00 - val_loss: 0.0463 - val_accuracy: 0.0000e+00\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.0000e+00 - val_loss: 0.0478 - val_accuracy: 0.0000e+00\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.0000e+00 - val_loss: 0.0413 - val_accuracy: 0.0000e+00\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.0000e+00 - val_loss: 0.0492 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.0000e+00 - val_loss: 0.0437 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.0000e+00 - val_loss: 0.0430 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0658 - accuracy: 0.0000e+00 - val_loss: 0.0436 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.0000e+00 - val_loss: 0.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.0000e+00 - val_loss: 0.0443 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.0000e+00 - val_loss: 0.0436 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.0000e+00 - val_loss: 0.0475 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.0000e+00 - val_loss: 0.0396 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.0000e+00 - val_loss: 0.0456 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.0000e+00 - val_loss: 0.0455 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.0000e+00 - val_loss: 0.0502 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0000e+00 - val_loss: 0.0366 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.0000e+00 - val_loss: 0.0427 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.0000e+00 - val_loss: 0.0466 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.0000e+00 - val_loss: 0.0442 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.0000e+00 - val_loss: 0.0460 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.0000e+00 - val_loss: 0.0362 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "TOetE3bBOFBM",
        "outputId": "f25bd730-00d1-4bd3-990d-79df09270bf8"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.ylim(0, 1.2)\r\n",
        "plt.plot(History.history['loss'])\r\n",
        "plt.plot(History.history['val_loss'])\r\n",
        "plt.plot(History.history['accuracy'])\r\n",
        "plt.plot(History.history['val_accuracy'])\r\n",
        "plt.legend(['loss','val_loss','accuracy','val_accuracy'])\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr3j-Ld3O1aM",
        "outputId": "7e1a35ec-160a-41bf-cb30-ed6cc971d9da"
      },
      "source": [
        "loss, accuracy = Model_iris.evaluate(X_test, y_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2t4wBFSPabN",
        "outputId": "ab16d6a4-b6e3-43d5-f972-baad95b46e1b"
      },
      "source": [
        "import numpy as np\r\n",
        "np.set_printoptions(suppress=True, precision=5)\r\n",
        "Model_iris.predict(X_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99823, 0.00177, 0.     ],\n",
              "       [0.99753, 0.00247, 0.     ],\n",
              "       [0.00141, 0.99832, 0.00027],\n",
              "       [0.00001, 0.00068, 0.99931],\n",
              "       [0.9984 , 0.0016 , 0.     ],\n",
              "       [0.00066, 0.99883, 0.00051],\n",
              "       [0.00009, 0.01264, 0.98728],\n",
              "       [0.99848, 0.00152, 0.     ],\n",
              "       [0.00002, 0.00251, 0.99747],\n",
              "       [0.99814, 0.00186, 0.     ],\n",
              "       [0.00142, 0.89764, 0.10094],\n",
              "       [0.00005, 0.00698, 0.99296],\n",
              "       [0.00085, 0.99279, 0.00636],\n",
              "       [0.99854, 0.00146, 0.     ],\n",
              "       [0.9984 , 0.0016 , 0.     ],\n",
              "       [0.00096, 0.98951, 0.00953],\n",
              "       [0.00118, 0.96754, 0.03129],\n",
              "       [0.99827, 0.00173, 0.     ],\n",
              "       [0.00078, 0.99566, 0.00356],\n",
              "       [0.99844, 0.00156, 0.     ],\n",
              "       [0.99815, 0.00185, 0.     ],\n",
              "       [0.99818, 0.00182, 0.     ],\n",
              "       [0.00003, 0.00322, 0.99675],\n",
              "       [0.99828, 0.00172, 0.     ],\n",
              "       [0.00028, 0.0595 , 0.94022],\n",
              "       [0.00024, 0.04698, 0.95278],\n",
              "       [0.99843, 0.00157, 0.     ],\n",
              "       [0.00109, 0.97867, 0.02025],\n",
              "       [0.00108, 0.98055, 0.01837],\n",
              "       [0.00033, 0.07187, 0.92781],\n",
              "       [0.99847, 0.00153, 0.     ],\n",
              "       [0.00102, 0.98494, 0.01404],\n",
              "       [0.99846, 0.00154, 0.     ],\n",
              "       [0.00147, 0.66837, 0.33016],\n",
              "       [0.00103, 0.98381, 0.01517],\n",
              "       [0.00057, 0.99893, 0.0005 ],\n",
              "       [0.00001, 0.00083, 0.99916],\n",
              "       [0.00069, 0.99811, 0.0012 ],\n",
              "       [0.99833, 0.00167, 0.     ],\n",
              "       [0.00105, 0.98513, 0.01382],\n",
              "       [0.00001, 0.00093, 0.99906],\n",
              "       [0.99802, 0.00198, 0.     ],\n",
              "       [0.00006, 0.00767, 0.99228],\n",
              "       [0.00003, 0.00324, 0.99673],\n",
              "       [0.00008, 0.01237, 0.98754]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg9L_R6aPnIL",
        "outputId": "5c9ea87d-c9b1-4658-8817-af0b0deefde6"
      },
      "source": [
        "y_hat = Model_iris.predict_classes(X_test)\r\n",
        "y_hat"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciu-lYYtPzPb",
        "outputId": "5176d1c5-87cf-4287-f41a-5eb938e40c12"
      },
      "source": [
        "np.argmax(Model_iris.predict(X_test), axis=1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE1OtljPP48D",
        "outputId": "ced1010c-de8d-45dc-966c-09724eba2256"
      },
      "source": [
        "y = np.argmax(y_test, axis=1)\r\n",
        "y"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYn-xAiDQp3b",
        "outputId": "263222e5-4625-48b9-bc9e-8f2ee8a0829a"
      },
      "source": [
        "np.argmax(y_test, axis=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C92Xb4VcQs4x",
        "outputId": "56c0d240-607e-4700-9c90-3fd5638b29e2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "\r\n",
        "confusion_matrix(y, y_hat)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17,  0,  0],\n",
              "       [ 0, 14,  0],\n",
              "       [ 0,  1, 13]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrfJZ5gOQ7y6",
        "outputId": "949c1340-2d0e-44dd-e7be-f6ec1ee20d11"
      },
      "source": [
        "print(classification_report(y, y_hat,\r\n",
        "                            target_names =['setosa', 'virginica','versicolor']))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        17\n",
            "   virginica       0.93      1.00      0.97        14\n",
            "  versicolor       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_e6I-FhRESa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}