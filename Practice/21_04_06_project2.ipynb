{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4feature_extract.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIlZV1THi_pn"
      },
      "source": [
        "import keras \n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1etUpmWoh3xe"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mwxvdcNku38"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print(y_train.shape,  y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF7cSyVFh5_9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=2045)\n",
        "\n",
        "print(X_train.shape, y_train.shape, '/', X_valid.shape, y_valid.shape, '/', X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vau1rY5DLt_3"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet', include_top = False, input_shape=(32,32, 3))   ######### input_shape #########\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEoMFNiXtjxn"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "datagen = ImageDataGenerator(rescale = 1./255)\n",
        "batch_size =32  ########## 32,32,3 shape에서의 32\n",
        "\n",
        "def extract_features(x, y, sample_count):\n",
        "  features = np.zeros(shape = (sample_count, 1, 1, 512)) ################ summary 마지막 노드 확인####################\n",
        "  labels = np.zeros(shape = (sample_count, 10))              ################ binary or categorical  #####\n",
        "\n",
        "  generator = datagen.flow(x, y)  ####### binary or categorical ###########\n",
        "\n",
        "  i = 0\n",
        "  for input_batch, label_batch in generator:\n",
        "    features_batch = conv_base.predict(input_batch)\n",
        "    features[ i*batch_size : (i+1)*batch_size ] = features_batch\n",
        "    labels [ i*batch_size : (i+1)*batch_size ] = label_batch\n",
        "    i += 1\n",
        "    if i * batch_size >= sample_count:\n",
        "      break\n",
        "  return features, labels\n",
        "\n",
        "X_train, y_train = extract_features(X_train, y_train, 35000)\n",
        "X_valid, y_valid = extract_features(X_valid, y_valid, 15000)\n",
        "X_test, y_test = extract_features(X_test, y_test, 10000)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrkQbjcT6T-M"
      },
      "source": [
        "# def extract_features(x, y, sample_count):\n",
        "#   features = np.zeros(shape =(sample_count, 1, 1, 512))\n",
        "#   labels = np.zeros(shape =(sample_count, 10))\n",
        "\n",
        "#   features_batch = conv_base.predict(x)\n",
        "#   features_batch = features\n",
        "#   labels = y\n",
        "#   return features, labels\n",
        "\n",
        "\n",
        "\n",
        "# X_train, y_train = extract_features(X_train, y_train, 35000)\n",
        "# X_valid, y_valid = extract_features(X_valid, y_valid, 15000)\n",
        "# X_test, y_test = extract_features(X_test, y_test, 10000)\n",
        "\n",
        "# print(X_train.shape, y_train.shape)\n",
        "# print(X_valid.shape, y_valid.shape)\n",
        "# print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f2BU-uSVuyw"
      },
      "source": [
        "X_train = np.reshape(X_train, (35000, 1*1*512))       ########## 데이터 크기 바꿔주기\n",
        "X_valid = np.reshape(X_valid, (15000, 1*1*512))\n",
        "X_test = np.reshape(X_test, (10000, 1*1*512))\n",
        "\n",
        "X_train.shape, X_valid.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Zq6i74WJ_Z"
      },
      "source": [
        "from keras import models, layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation ='relu', input_dim=(1*1*512)))  ######### input_dim #################\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax')) ######### sigmoid or softmax ############\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  ############# binary or categorical ########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSTXFJcgYz6I"
      },
      "source": [
        "%%time\n",
        "Hist = model.fit(X_train, y_train, epochs=100, batch_size=20, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHbkpvjbZLES"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Loss = {:.5f}'.format(loss))\n",
        "print('Accuracy = {:.5f}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJA0hAvIZRXr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(Hist.history['loss']) + 1)\n",
        "plt.figure(figsize = (9, 6))\n",
        "plt.plot(epochs, Hist.history['loss'])\n",
        "plt.plot(epochs, Hist.history['val_loss'])\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "epochs = range(1, len(Hist.history['loss']) + 1)\n",
        "plt.figure(figsize = (9, 6))\n",
        "plt.plot(epochs, Hist.history['accuracy'])\n",
        "plt.plot(epochs, Hist.history['val_accuracy'])\n",
        "plt.title('Training & Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training accuracy', 'Validation accuracy'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}