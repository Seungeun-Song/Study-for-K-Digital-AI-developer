{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmn8m4f8V9qb"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2JgsVZxov06",
        "outputId": "84f6e646-fc69-405a-afd4-40e9cf1ebbea"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtKhiK3ZoxnQ",
        "outputId": "1fb911a6-bd56-4c4b-848d-2c42eb7ca6ce"
      },
      "source": [
        "X_train = X_train.astype('float32')/255.\n",
        "X_test = X_test.astype('float32')/255.\n",
        "\n",
        "X_train = X_train.reshape(60000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "009M_dD9pTtQ"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "encoded = Dense(256, activation='elu')(input_img)\n",
        "encoded = Dense(128, activation='elu')(encoded)\n",
        "\n",
        "mean = Dense(2, name='mean')(encoded)\n",
        "log_var = Dense(2, name='var')(encoded)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk7GbDX9846t"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import Lambda\n",
        "\n",
        "def sampling(args):\n",
        "  mean, log_var = args\n",
        "  epsilon = K.random_normal(shape=(100,2), mean=0., stddev=1.0)\n",
        "  return mean + K.exp(log_var)*epsilon\n",
        "\n",
        "z = Lambda(sampling, output_shape=(2,))([mean, log_var])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_GlpzxlA0Qm",
        "outputId": "a38afc4f-6332-425e-df32-cc77f96e8728"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "encoder = Model(input_img, mean)\n",
        "encoder.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "mean (Dense)                 (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 234,114\n",
            "Trainable params: 234,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2_ekBmFBMIc",
        "outputId": "7e8c040b-0e57-420a-fc44-edad6ee106ff"
      },
      "source": [
        "decoder_1 = Dense(128, activation='elu')\n",
        "decoder_2 = Dense(256, activation='elu')\n",
        "decoder_3 = Dense(784, activation='sigmoid')\n",
        "\n",
        "z_sample = decoder_1(z)\n",
        "z_sample = decoder_2(z_sample)\n",
        "z_sample = decoder_3(z_sample)\n",
        "z_sample.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8jz4_LOBtLs",
        "outputId": "cb846b8e-bc51-4946-f6c4-a884011015fd"
      },
      "source": [
        "z_sampe = Dense(128,activation='elu')(z)\n",
        "z_sampe = Dense(256, activation='elu')(z_sampe)\n",
        "z_sampe = Dense(784, activation='sigmoid')(z_sampe)\n",
        "z_sampe.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFvbIucgCBr8",
        "outputId": "fe2c6477-c533-46ea-db04-a1fa52df4219"
      },
      "source": [
        "decoder_input = Input(shape = (2,))\n",
        "\n",
        "y_gen = decoder_1(decoder_input)\n",
        "y_gen = decoder_2(y_gen)\n",
        "y_gen = decoder_3(y_gen)\n",
        "\n",
        "generator = Model(decoder_input, y_gen)\n",
        "generator.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  384       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  33024     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  201488    \n",
            "=================================================================\n",
            "Total params: 234,896\n",
            "Trainable params: 234,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKk-Aw3qH2-K",
        "outputId": "de62027e-9043-49d3-9f24-37de9ab04a0d"
      },
      "source": [
        "vae = Model(input_img, z_sample)\n",
        "vae.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 784)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          200960      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "mean (Dense)                    (None, 2)            258         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "var (Dense)                     (None, 2)            258         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (100, 2)             0           mean[0][0]                       \n",
            "                                                                 var[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 multiple             384         lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 multiple             33024       dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 multiple             201488      dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 469,268\n",
            "Trainable params: 469,268\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lsCFbmtIeaw"
      },
      "source": [
        "from keras import objectives\n",
        "\n",
        "reconstruction_loss = objectives.binary_crossentropy(input_img, z_sample)\n",
        "kl_loss = 0.0005 * K.mean(K.square(mean) + K.exp(log_var) - log_var - 1, axis = -1)\n",
        "vae_loss = reconstruction_loss + kl_loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDaj5_SAJotq"
      },
      "source": [
        "vae.add_loss(vae_loss)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV98VzcXJvo4"
      },
      "source": [
        "vae.compile(optimizer = 'adam')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRSXgZt9JyLY",
        "outputId": "1ea1d859-8bff-406e-e936-ee6da3c4d87f"
      },
      "source": [
        "%%time\n",
        "vae.fit(X_train, shuffle = True,  epochs = 300, batch_size = 100, validation_data = (X_test, None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "600/600 [==============================] - 8s 12ms/step - loss: 0.2763 - val_loss: 0.2164\n",
            "Epoch 2/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2140 - val_loss: 0.2077\n",
            "Epoch 3/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2056 - val_loss: 0.2009\n",
            "Epoch 4/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1992 - val_loss: 0.1956\n",
            "Epoch 5/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1947 - val_loss: 0.1920\n",
            "Epoch 6/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1911 - val_loss: 0.1886\n",
            "Epoch 7/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1876 - val_loss: 0.1870\n",
            "Epoch 8/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1860 - val_loss: 0.1853\n",
            "Epoch 9/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1839 - val_loss: 0.1843\n",
            "Epoch 10/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1832 - val_loss: 0.1827\n",
            "Epoch 11/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1819 - val_loss: 0.1818\n",
            "Epoch 12/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1816 - val_loss: 0.1811\n",
            "Epoch 13/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1804 - val_loss: 0.1812\n",
            "Epoch 14/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1805 - val_loss: 0.1800\n",
            "Epoch 15/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1793 - val_loss: 0.1799\n",
            "Epoch 16/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1789 - val_loss: 0.1800\n",
            "Epoch 17/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1790 - val_loss: 0.1791\n",
            "Epoch 18/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1779 - val_loss: 0.1787\n",
            "Epoch 19/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1774 - val_loss: 0.1780\n",
            "Epoch 20/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1770 - val_loss: 0.1783\n",
            "Epoch 21/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1770 - val_loss: 0.1782\n",
            "Epoch 22/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1764 - val_loss: 0.1777\n",
            "Epoch 23/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1765 - val_loss: 0.1777\n",
            "Epoch 24/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1755 - val_loss: 0.1770\n",
            "Epoch 25/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1757 - val_loss: 0.1777\n",
            "Epoch 26/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1746 - val_loss: 0.1771\n",
            "Epoch 27/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1749 - val_loss: 0.1765\n",
            "Epoch 28/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1743 - val_loss: 0.1761\n",
            "Epoch 29/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1741 - val_loss: 0.1765\n",
            "Epoch 30/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1744 - val_loss: 0.1753\n",
            "Epoch 31/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1741 - val_loss: 0.1753\n",
            "Epoch 32/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1735 - val_loss: 0.1754\n",
            "Epoch 33/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1728 - val_loss: 0.1760\n",
            "Epoch 34/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1728 - val_loss: 0.1754\n",
            "Epoch 35/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1724 - val_loss: 0.1756\n",
            "Epoch 36/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1723 - val_loss: 0.1749\n",
            "Epoch 37/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1721 - val_loss: 0.1754\n",
            "Epoch 38/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1723 - val_loss: 0.1749\n",
            "Epoch 39/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1720 - val_loss: 0.1750\n",
            "Epoch 40/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1722 - val_loss: 0.1746\n",
            "Epoch 41/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1724 - val_loss: 0.1748\n",
            "Epoch 42/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1716 - val_loss: 0.1745\n",
            "Epoch 43/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1712 - val_loss: 0.1747\n",
            "Epoch 44/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1707 - val_loss: 0.1742\n",
            "Epoch 45/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1713 - val_loss: 0.1756\n",
            "Epoch 46/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1711 - val_loss: 0.1741\n",
            "Epoch 47/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1706 - val_loss: 0.1743\n",
            "Epoch 48/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1710 - val_loss: 0.1741\n",
            "Epoch 49/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1705 - val_loss: 0.1744\n",
            "Epoch 50/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1708 - val_loss: 0.1740\n",
            "Epoch 51/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1707 - val_loss: 0.1740\n",
            "Epoch 52/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1705 - val_loss: 0.1737\n",
            "Epoch 53/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1700 - val_loss: 0.1745\n",
            "Epoch 54/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1703 - val_loss: 0.1743\n",
            "Epoch 55/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1699 - val_loss: 0.1746\n",
            "Epoch 56/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1699 - val_loss: 0.1733\n",
            "Epoch 57/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1697 - val_loss: 0.1734\n",
            "Epoch 58/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1697 - val_loss: 0.1735\n",
            "Epoch 59/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1696 - val_loss: 0.1735\n",
            "Epoch 60/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1695 - val_loss: 0.1734\n",
            "Epoch 61/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1693 - val_loss: 0.1741\n",
            "Epoch 62/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1696 - val_loss: 0.1741\n",
            "Epoch 63/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1694 - val_loss: 0.1733\n",
            "Epoch 64/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1690 - val_loss: 0.1739\n",
            "Epoch 65/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1693 - val_loss: 0.1732\n",
            "Epoch 66/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1697 - val_loss: 0.1731\n",
            "Epoch 67/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1689 - val_loss: 0.1728\n",
            "Epoch 68/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1690 - val_loss: 0.1737\n",
            "Epoch 69/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1684 - val_loss: 0.1731\n",
            "Epoch 70/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1682 - val_loss: 0.1738\n",
            "Epoch 71/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1687 - val_loss: 0.1737\n",
            "Epoch 72/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1685 - val_loss: 0.1739\n",
            "Epoch 73/300\n",
            "600/600 [==============================] - 7s 11ms/step - loss: 0.1685 - val_loss: 0.1738\n",
            "Epoch 74/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1688 - val_loss: 0.1730\n",
            "Epoch 75/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1679 - val_loss: 0.1728\n",
            "Epoch 76/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1681 - val_loss: 0.1733\n",
            "Epoch 77/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1681 - val_loss: 0.1730\n",
            "Epoch 78/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1678 - val_loss: 0.1726\n",
            "Epoch 79/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1678 - val_loss: 0.1739\n",
            "Epoch 80/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1680 - val_loss: 0.1735\n",
            "Epoch 81/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1680 - val_loss: 0.1732\n",
            "Epoch 82/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1678 - val_loss: 0.1745\n",
            "Epoch 83/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1681 - val_loss: 0.1730\n",
            "Epoch 84/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1678 - val_loss: 0.1735\n",
            "Epoch 85/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1676 - val_loss: 0.1738\n",
            "Epoch 86/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1675 - val_loss: 0.1730\n",
            "Epoch 87/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1673 - val_loss: 0.1732\n",
            "Epoch 88/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1675 - val_loss: 0.1734\n",
            "Epoch 89/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1674 - val_loss: 0.1731\n",
            "Epoch 90/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1677 - val_loss: 0.1735\n",
            "Epoch 91/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1673 - val_loss: 0.1732\n",
            "Epoch 92/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1670 - val_loss: 0.1728\n",
            "Epoch 93/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1665 - val_loss: 0.1732\n",
            "Epoch 94/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1673 - val_loss: 0.1730\n",
            "Epoch 95/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1670 - val_loss: 0.1735\n",
            "Epoch 96/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1673 - val_loss: 0.1734\n",
            "Epoch 97/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1670 - val_loss: 0.1728\n",
            "Epoch 98/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1669 - val_loss: 0.1731\n",
            "Epoch 99/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1668 - val_loss: 0.1727\n",
            "Epoch 100/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1667 - val_loss: 0.1734\n",
            "Epoch 101/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1669 - val_loss: 0.1730\n",
            "Epoch 102/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1670 - val_loss: 0.1728\n",
            "Epoch 103/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1666 - val_loss: 0.1733\n",
            "Epoch 104/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1667 - val_loss: 0.1735\n",
            "Epoch 105/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1666 - val_loss: 0.1726\n",
            "Epoch 106/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1661 - val_loss: 0.1727\n",
            "Epoch 107/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1666 - val_loss: 0.1728\n",
            "Epoch 108/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1667 - val_loss: 0.1731\n",
            "Epoch 109/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1666 - val_loss: 0.1733\n",
            "Epoch 110/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1664 - val_loss: 0.1730\n",
            "Epoch 111/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1661 - val_loss: 0.1732\n",
            "Epoch 112/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1665 - val_loss: 0.1732\n",
            "Epoch 113/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1660 - val_loss: 0.1730\n",
            "Epoch 114/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1661 - val_loss: 0.1729\n",
            "Epoch 115/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1664 - val_loss: 0.1734\n",
            "Epoch 116/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1662 - val_loss: 0.1730\n",
            "Epoch 117/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1661 - val_loss: 0.1741\n",
            "Epoch 118/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1662 - val_loss: 0.1731\n",
            "Epoch 119/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1660 - val_loss: 0.1727\n",
            "Epoch 120/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1662 - val_loss: 0.1728\n",
            "Epoch 121/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1663 - val_loss: 0.1733\n",
            "Epoch 122/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1659 - val_loss: 0.1729\n",
            "Epoch 123/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1658 - val_loss: 0.1726\n",
            "Epoch 124/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1653 - val_loss: 0.1733\n",
            "Epoch 125/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1655 - val_loss: 0.1733\n",
            "Epoch 126/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1655 - val_loss: 0.1729\n",
            "Epoch 127/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1658 - val_loss: 0.1730\n",
            "Epoch 128/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1655 - val_loss: 0.1729\n",
            "Epoch 129/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1658 - val_loss: 0.1732\n",
            "Epoch 130/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1652 - val_loss: 0.1733\n",
            "Epoch 131/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1660 - val_loss: 0.1729\n",
            "Epoch 132/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1652 - val_loss: 0.1731\n",
            "Epoch 133/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1659 - val_loss: 0.1728\n",
            "Epoch 134/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1655 - val_loss: 0.1729\n",
            "Epoch 135/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1656 - val_loss: 0.1730\n",
            "Epoch 136/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1651 - val_loss: 0.1731\n",
            "Epoch 137/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1648 - val_loss: 0.1736\n",
            "Epoch 138/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1657 - val_loss: 0.1731\n",
            "Epoch 139/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1656 - val_loss: 0.1734\n",
            "Epoch 140/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1652 - val_loss: 0.1725\n",
            "Epoch 141/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1656 - val_loss: 0.1733\n",
            "Epoch 142/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1655 - val_loss: 0.1730\n",
            "Epoch 143/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1649 - val_loss: 0.1733\n",
            "Epoch 144/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1653 - val_loss: 0.1735\n",
            "Epoch 145/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1652 - val_loss: 0.1735\n",
            "Epoch 146/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1649 - val_loss: 0.1732\n",
            "Epoch 147/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1654 - val_loss: 0.1732\n",
            "Epoch 148/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1650 - val_loss: 0.1729\n",
            "Epoch 149/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1649 - val_loss: 0.1733\n",
            "Epoch 150/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1652 - val_loss: 0.1731\n",
            "Epoch 151/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1649 - val_loss: 0.1733\n",
            "Epoch 152/300\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1653 - val_loss: 0.1731\n",
            "Epoch 153/300\n",
            "600/600 [==============================] - ETA: 0s - loss: 0.1652"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwtZUs_FJ5iR"
      },
      "source": [
        "X_test_latent= encoder.predict(X_test, batch_size=100)\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.scatter(X_test_latent[:,0], X_test_latent[:,1], c=y_test)\n",
        "plr.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W83_hcvtMdNo"
      },
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "n=20\n",
        "digit_size=28\n",
        "figure = np.zeros((digit_size*n, digit_size*n))\n",
        "\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "  for j, xi in enumerate(grid_y):\n",
        "    z_sample = np.array([[xi, yi]])\n",
        "    x_decoded = generator.predict(z_sample)\n",
        "    digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "    figure[i * digit_size: (i + 1) * digit_size, j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(figure, cmap = 'Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtbi9uspN0I_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}