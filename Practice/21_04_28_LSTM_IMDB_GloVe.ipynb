{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ig1rdYbPRN4",
        "outputId": "ce3ce86a-d376-4baa-8bff-ecc4f6471d81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj1VWWa3P_NV",
        "outputId": "ec80a692-4a16-4305-f17d-298e481d6e84"
      },
      "source": [
        "!ls -l /content/drive/My\\ Drive/Colab\\ Notebooks/datasets/IMDB.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 60711700 Apr 28 11:33 '/content/drive/My Drive/Colab Notebooks/datasets/IMDB.zip'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGgzAM0PQEdb"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Colab\\ Notebooks/datasets/IMDB.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsdAyNgcQg5a"
      },
      "source": [
        "import os\n",
        "\n",
        "imdb_dir = 'aclImdb'\n",
        "train_dir=os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels=[]\n",
        "texts=[]\n",
        "\n",
        "for label_type in ['neg','pos']:\n",
        "  dir_name = os.path.join(train_dir, label_type)\n",
        "  for fname in os.listdir(dir_name):\n",
        "    if fname[-4:] =='.txt':\n",
        "      f = open(os.path.join(dir_name, fname), encoding='utf8')\n",
        "      texts.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        labels.append(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_XRPb7JS74S",
        "outputId": "1ba48329-460b-4753-bc49-a5e561c249c1"
      },
      "source": [
        "len(texts), len(labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_BglrXuS9iK"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "maxlen=2000\n",
        "max_words=10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_text(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('%s개의 고유한 토큰을 찾았습니다.' % len(word_index))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}