{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_mnist_송승은.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PORZqEBOOMeE",
        "outputId": "6eaff80e-1036-4924-84d8-6a8db3540264"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NmoFKE7OXS8",
        "outputId": "2923ce27-f94f-4990-aa92-c1ea82995b7f"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgL1H0BCOgik",
        "outputId": "ea025e9a-90b3-4da9-bc8d-456eb12322fe"
      },
      "source": [
        "print(len(X_train))\n",
        "print(X_train.shape)\n",
        "\n",
        "print(len(y_train))\n",
        "print(y_train[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "(60000, 28, 28)\n",
            "60000\n",
            "[9 0 0 3 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a53SLOapOqaj",
        "outputId": "73f30579-21f3-4f9b-e755-fc1dcec9c5be"
      },
      "source": [
        "print(len(X_test))\n",
        "print(X_test.shape)\n",
        "\n",
        "print(len(y_test))\n",
        "print(y_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "(10000, 28, 28)\n",
            "10000\n",
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XcTe-EjHO10a",
        "outputId": "dff0ea06-9d37-4f2e-ef3a-2438242f1e42"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit = X_train[0]\n",
        "plt.imshow(digit, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0HXQK8uO9qa",
        "outputId": "39a718ba-30cd-4d24-eaa5-3acdb08ca026"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(linewidth=150)\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFiOiTVlPFfC",
        "outputId": "c8d03a23-d8e9-45e0-86cc-6210f5a9542f"
      },
      "source": [
        "X_train = X_train.reshape((60000, 28*28))  \n",
        "X_test = X_test.reshape((10000, 28*28))\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2E4Gn4EPgwx",
        "outputId": "39f128df-073e-4cc8-f9e1-fa039737d0d2"
      },
      "source": [
        "X_train = X_train.astype(float)/255\n",
        "X_test = X_test.astype(float)/255\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157 0.         0.         0.05098039 0.28627451 0.         0.         0.00392157\n",
            " 0.01568627 0.         0.         0.         0.         0.00392157 0.00392157 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
            " 0.21176471 0.         0.         0.         0.00392157 0.01176471 0.01568627 0.         0.         0.01176471 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.4        0.8\n",
            " 0.69019608 0.5254902  0.56470588 0.48235294 0.09019608 0.         0.         0.         0.         0.04705882 0.03921569 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.60784314 0.9254902  0.81176471 0.69803922 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608 0.30196078 0.50980392 0.28235294\n",
            " 0.05882353 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157\n",
            " 0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882 0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118\n",
            " 0.34509804 0.6745098  0.25882353 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157\n",
            " 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922 0.8745098  0.8745098  0.84313725 0.83529412 0.64313725\n",
            " 0.49803922 0.48235294 0.76862745 0.89803922 0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765 0.92156863 0.89019608 0.87843137\n",
            " 0.87058824 0.87843137 0.86666667 0.8745098  0.96078431 0.67843137 0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059 0.70588235\n",
            " 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118 0.79215686 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00392157 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255 0.85490196\n",
            " 0.75294118 0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.38823529 0.95686275 0.87058824\n",
            " 0.8627451  0.85490196 0.79607843 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451  0.96078431 0.46666667 0.65490196 0.21960784\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.         0.21568627\n",
            " 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647 0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784\n",
            " 0.36078431 0.         0.         0.         0.00392157 0.01568627 0.02352941 0.02745098 0.00784314 0.         0.         0.         0.\n",
            " 0.         0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353 0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
            " 0.85490196 1.         0.30196078 0.         0.         0.01176471 0.         0.         0.         0.         0.         0.         0.\n",
            " 0.24313725 0.56862745 0.8        0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627 0.82745098 0.85490196 0.87843137 0.8745098\n",
            " 0.85882353 0.84313725 0.87843137 0.95686275 0.62352941 0.         0.         0.         0.         0.         0.07058824 0.17254902 0.32156863\n",
            " 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078 0.87843137 0.91764706\n",
            " 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333 0.84313725 0.         0.         0.22352941 0.73333333 0.81568627 0.87843137\n",
            " 0.86666667 0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
            " 1.         1.         0.86666667 0.91764706 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.         0.01176471 0.79215686 0.89411765\n",
            " 0.87843137 0.86666667 0.82745098 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451  0.94117647 0.31372549 0.58823529 1.\n",
            " 0.89803922 0.86666667 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784 0.87058824 0.89411765 0.88235294 0.         0.38431373\n",
            " 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804\n",
            " 0.25490196 0.28627451 0.41568627 0.45882353 0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137 0.89803922\n",
            " 0.11372549 0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
            " 0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431 0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824 0.8627451\n",
            " 0.86666667 0.90196078 0.2627451  0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902 0.7254902  0.74509804 0.76078431 0.75294118\n",
            " 0.79215686 0.83921569 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765\n",
            " 0.6745098  0.70980392 0.80392157 0.80784314 0.45098039 0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745\n",
            " 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961 0.76470588 0.74901961 0.77647059\n",
            " 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765 0.82352941 0.36078431 0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
            " 0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784 0.82352941\n",
            " 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.         0.00784314 0.         0.         0.\n",
            " 0.25882353 0.78431373 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961\n",
            " 0.70196078 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353 0.38823529 0.22745098 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPijZeqmPjZc",
        "outputId": "404d0703-2ca8-4bc3-b4e5-3a30e10dd792"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(y_train[:5])\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De2hwbntuNPb"
      },
      "source": [
        "# L2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZnoEE2ULFtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b609b6-e806-4cf4-f6c5-81990c23a27b"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "\n",
        "L2 = models.Sequential()\n",
        "L2.add(layers.Dense(512, activation='relu', input_shape=(28*28,), \n",
        "                       kernel_regularizer = regularizers.l2(0.00001)))\n",
        "L2.add(layers.Dense(256, activation='relu',\n",
        "                       kernel_regularizer = regularizers.l2(0.00001)))\n",
        "L2.add(layers.Dense(10, activation='softmax'))\n",
        "L2.summary()\n",
        "\n",
        "Hist_L2 = L2.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnaRa4A7SwdO",
        "outputId": "d22e45d6-50bd-4e7f-b38e-06257998c9bc"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "ex = EarlyStopping(monitor='val_accuracy', mode='max', patience=150, verbose = 1)\n",
        "mc = ModelCheckpoint('best-L2.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "%time\n",
        "Hist_L2 = L2.fit(X_train, y_train, epochs=500, batch_size=128, validation_split=0.2, callbacks=[ex, mc], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 5.96 µs\n",
            "Epoch 1/500\n",
            "375/375 [==============================] - 5s 6ms/step - loss: 0.7927 - accuracy: 0.7196 - val_loss: 0.4124 - val_accuracy: 0.8521\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.85208, saving model to best-DR_BN.h5\n",
            "Epoch 2/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4153 - accuracy: 0.8486 - val_loss: 0.3720 - val_accuracy: 0.8718\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.85208 to 0.87183, saving model to best-DR_BN.h5\n",
            "Epoch 3/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3626 - accuracy: 0.8701 - val_loss: 0.3526 - val_accuracy: 0.8736\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.87183 to 0.87358, saving model to best-DR_BN.h5\n",
            "Epoch 4/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3311 - accuracy: 0.8816 - val_loss: 0.4462 - val_accuracy: 0.8447\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.87358\n",
            "Epoch 5/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3096 - accuracy: 0.8909 - val_loss: 0.3387 - val_accuracy: 0.8858\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.87358 to 0.88583, saving model to best-DR_BN.h5\n",
            "Epoch 6/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2938 - accuracy: 0.8935 - val_loss: 0.3776 - val_accuracy: 0.8775\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.88583\n",
            "Epoch 7/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2839 - accuracy: 0.9004 - val_loss: 0.3565 - val_accuracy: 0.8840\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.88583\n",
            "Epoch 8/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2678 - accuracy: 0.9054 - val_loss: 0.3474 - val_accuracy: 0.8920\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.88583 to 0.89200, saving model to best-DR_BN.h5\n",
            "Epoch 9/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2610 - accuracy: 0.9075 - val_loss: 0.3689 - val_accuracy: 0.8763\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.89200\n",
            "Epoch 10/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2521 - accuracy: 0.9118 - val_loss: 0.3716 - val_accuracy: 0.8791\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.89200\n",
            "Epoch 11/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2457 - accuracy: 0.9124 - val_loss: 0.3417 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.89200 to 0.89275, saving model to best-DR_BN.h5\n",
            "Epoch 12/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2438 - accuracy: 0.9153 - val_loss: 0.3735 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.89275\n",
            "Epoch 13/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2420 - accuracy: 0.9152 - val_loss: 0.4212 - val_accuracy: 0.8752\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.89275\n",
            "Epoch 14/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2257 - accuracy: 0.9203 - val_loss: 0.3540 - val_accuracy: 0.8906\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.89275\n",
            "Epoch 15/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2233 - accuracy: 0.9220 - val_loss: 0.3928 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89275\n",
            "Epoch 16/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2225 - accuracy: 0.9227 - val_loss: 0.3700 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.89275 to 0.89425, saving model to best-DR_BN.h5\n",
            "Epoch 17/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2200 - accuracy: 0.9245 - val_loss: 0.3934 - val_accuracy: 0.8877\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.89425\n",
            "Epoch 18/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2112 - accuracy: 0.9283 - val_loss: 0.4084 - val_accuracy: 0.8884\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.89425\n",
            "Epoch 19/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2128 - accuracy: 0.9269 - val_loss: 0.3853 - val_accuracy: 0.8931\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.89425\n",
            "Epoch 20/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2007 - accuracy: 0.9330 - val_loss: 0.4485 - val_accuracy: 0.8855\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89425\n",
            "Epoch 21/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2010 - accuracy: 0.9323 - val_loss: 0.4108 - val_accuracy: 0.8895\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.89425\n",
            "Epoch 22/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1928 - accuracy: 0.9337 - val_loss: 0.4423 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89425\n",
            "Epoch 23/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1967 - accuracy: 0.9346 - val_loss: 0.4162 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89425\n",
            "Epoch 24/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1922 - accuracy: 0.9374 - val_loss: 0.4307 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89425\n",
            "Epoch 25/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1876 - accuracy: 0.9387 - val_loss: 0.4748 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89425\n",
            "Epoch 26/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1874 - accuracy: 0.9384 - val_loss: 0.4224 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89425\n",
            "Epoch 27/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1846 - accuracy: 0.9403 - val_loss: 0.4432 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89425\n",
            "Epoch 28/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1884 - accuracy: 0.9381 - val_loss: 0.4953 - val_accuracy: 0.8886\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89425\n",
            "Epoch 29/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1852 - accuracy: 0.9406 - val_loss: 0.4788 - val_accuracy: 0.8890\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89425\n",
            "Epoch 30/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1798 - accuracy: 0.9413 - val_loss: 0.4133 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89425\n",
            "Epoch 31/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1784 - accuracy: 0.9432 - val_loss: 0.4699 - val_accuracy: 0.8862\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89425\n",
            "Epoch 32/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1799 - accuracy: 0.9428 - val_loss: 0.4527 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.89425 to 0.89475, saving model to best-DR_BN.h5\n",
            "Epoch 33/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1761 - accuracy: 0.9423 - val_loss: 0.5003 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89475\n",
            "Epoch 34/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1738 - accuracy: 0.9440 - val_loss: 0.5335 - val_accuracy: 0.8687\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89475\n",
            "Epoch 35/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1709 - accuracy: 0.9471 - val_loss: 0.4892 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89475\n",
            "Epoch 36/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1674 - accuracy: 0.9480 - val_loss: 0.4915 - val_accuracy: 0.8914\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89475\n",
            "Epoch 37/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1649 - accuracy: 0.9493 - val_loss: 0.5194 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89475\n",
            "Epoch 38/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1685 - accuracy: 0.9468 - val_loss: 0.5582 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89475\n",
            "Epoch 39/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1662 - accuracy: 0.9495 - val_loss: 0.4936 - val_accuracy: 0.8839\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89475\n",
            "Epoch 40/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1625 - accuracy: 0.9484 - val_loss: 0.5370 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89475\n",
            "Epoch 41/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1631 - accuracy: 0.9487 - val_loss: 0.5766 - val_accuracy: 0.8841\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89475\n",
            "Epoch 42/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1620 - accuracy: 0.9509 - val_loss: 0.4778 - val_accuracy: 0.8924\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89475\n",
            "Epoch 43/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1546 - accuracy: 0.9529 - val_loss: 0.5616 - val_accuracy: 0.8926\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89475\n",
            "Epoch 44/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1566 - accuracy: 0.9528 - val_loss: 0.5746 - val_accuracy: 0.8813\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89475\n",
            "Epoch 45/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1531 - accuracy: 0.9528 - val_loss: 0.5413 - val_accuracy: 0.8918\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89475\n",
            "Epoch 46/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1524 - accuracy: 0.9534 - val_loss: 0.5518 - val_accuracy: 0.8864\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89475\n",
            "Epoch 47/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1556 - accuracy: 0.9518 - val_loss: 0.5604 - val_accuracy: 0.8922\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89475\n",
            "Epoch 48/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1545 - accuracy: 0.9536 - val_loss: 0.5675 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89475\n",
            "Epoch 49/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1510 - accuracy: 0.9552 - val_loss: 0.5514 - val_accuracy: 0.8912\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89475\n",
            "Epoch 50/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1505 - accuracy: 0.9553 - val_loss: 0.6762 - val_accuracy: 0.8729\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89475\n",
            "Epoch 51/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1475 - accuracy: 0.9566 - val_loss: 0.5855 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89475\n",
            "Epoch 52/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1539 - accuracy: 0.9537 - val_loss: 0.5327 - val_accuracy: 0.8921\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89475\n",
            "Epoch 53/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1512 - accuracy: 0.9549 - val_loss: 0.6142 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89475\n",
            "Epoch 54/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1491 - accuracy: 0.9548 - val_loss: 0.5869 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89475\n",
            "Epoch 55/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1465 - accuracy: 0.9567 - val_loss: 0.5478 - val_accuracy: 0.8911\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89475\n",
            "Epoch 56/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1455 - accuracy: 0.9575 - val_loss: 0.5625 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89475\n",
            "Epoch 57/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1435 - accuracy: 0.9580 - val_loss: 0.7282 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89475\n",
            "Epoch 58/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1494 - accuracy: 0.9582 - val_loss: 0.6328 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89475\n",
            "Epoch 59/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1434 - accuracy: 0.9589 - val_loss: 0.6065 - val_accuracy: 0.8835\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89475\n",
            "Epoch 60/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1417 - accuracy: 0.9595 - val_loss: 0.5913 - val_accuracy: 0.8898\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89475\n",
            "Epoch 61/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1451 - accuracy: 0.9578 - val_loss: 0.6127 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89475\n",
            "Epoch 62/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1454 - accuracy: 0.9592 - val_loss: 0.7751 - val_accuracy: 0.8699\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89475\n",
            "Epoch 63/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1401 - accuracy: 0.9603 - val_loss: 0.6147 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89475\n",
            "Epoch 64/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1431 - accuracy: 0.9595 - val_loss: 0.6877 - val_accuracy: 0.8865\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89475\n",
            "Epoch 65/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1390 - accuracy: 0.9602 - val_loss: 0.6184 - val_accuracy: 0.8903\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89475\n",
            "Epoch 66/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1371 - accuracy: 0.9621 - val_loss: 0.6653 - val_accuracy: 0.8904\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89475\n",
            "Epoch 67/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1372 - accuracy: 0.9621 - val_loss: 0.6247 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89475\n",
            "Epoch 68/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1372 - accuracy: 0.9624 - val_loss: 0.7308 - val_accuracy: 0.8823\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89475\n",
            "Epoch 69/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1369 - accuracy: 0.9613 - val_loss: 0.6465 - val_accuracy: 0.8895\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89475\n",
            "Epoch 70/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1384 - accuracy: 0.9608 - val_loss: 0.5938 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89475\n",
            "Epoch 71/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1307 - accuracy: 0.9640 - val_loss: 0.6726 - val_accuracy: 0.8909\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89475\n",
            "Epoch 72/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1350 - accuracy: 0.9646 - val_loss: 0.6444 - val_accuracy: 0.8903\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.89475\n",
            "Epoch 73/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1304 - accuracy: 0.9639 - val_loss: 0.6530 - val_accuracy: 0.8883\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.89475\n",
            "Epoch 74/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1320 - accuracy: 0.9644 - val_loss: 0.7014 - val_accuracy: 0.8809\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.89475\n",
            "Epoch 75/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1307 - accuracy: 0.9658 - val_loss: 0.7283 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.89475\n",
            "Epoch 76/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1393 - accuracy: 0.9632 - val_loss: 0.6842 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.89475\n",
            "Epoch 77/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1310 - accuracy: 0.9668 - val_loss: 0.6759 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.89475\n",
            "Epoch 78/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1300 - accuracy: 0.9647 - val_loss: 0.6917 - val_accuracy: 0.8899\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.89475\n",
            "Epoch 79/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1269 - accuracy: 0.9654 - val_loss: 0.7356 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.89475\n",
            "Epoch 80/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1292 - accuracy: 0.9660 - val_loss: 0.6800 - val_accuracy: 0.8861\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.89475\n",
            "Epoch 81/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1273 - accuracy: 0.9670 - val_loss: 0.6889 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.89475\n",
            "Epoch 82/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1272 - accuracy: 0.9667 - val_loss: 0.6901 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.89475\n",
            "Epoch 83/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1237 - accuracy: 0.9673 - val_loss: 0.7740 - val_accuracy: 0.8814\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.89475\n",
            "Epoch 84/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1264 - accuracy: 0.9667 - val_loss: 0.7794 - val_accuracy: 0.8808\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.89475\n",
            "Epoch 85/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1295 - accuracy: 0.9682 - val_loss: 0.7462 - val_accuracy: 0.8817\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.89475\n",
            "Epoch 86/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1261 - accuracy: 0.9671 - val_loss: 0.6728 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.89475\n",
            "Epoch 87/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1246 - accuracy: 0.9681 - val_loss: 0.7401 - val_accuracy: 0.8883\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.89475\n",
            "Epoch 88/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1266 - accuracy: 0.9678 - val_loss: 0.7696 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.89475\n",
            "Epoch 89/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1262 - accuracy: 0.9668 - val_loss: 0.7040 - val_accuracy: 0.8894\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.89475\n",
            "Epoch 90/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1252 - accuracy: 0.9685 - val_loss: 0.8235 - val_accuracy: 0.8696\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.89475\n",
            "Epoch 91/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1228 - accuracy: 0.9687 - val_loss: 0.7288 - val_accuracy: 0.8835\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.89475\n",
            "Epoch 92/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1234 - accuracy: 0.9687 - val_loss: 0.7092 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.89475\n",
            "Epoch 93/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1241 - accuracy: 0.9675 - val_loss: 0.7035 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.89475\n",
            "Epoch 94/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1233 - accuracy: 0.9692 - val_loss: 0.7257 - val_accuracy: 0.8900\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.89475\n",
            "Epoch 95/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1211 - accuracy: 0.9690 - val_loss: 0.7921 - val_accuracy: 0.8773\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.89475\n",
            "Epoch 96/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1217 - accuracy: 0.9699 - val_loss: 0.7539 - val_accuracy: 0.8865\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.89475\n",
            "Epoch 97/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1231 - accuracy: 0.9689 - val_loss: 0.7614 - val_accuracy: 0.8773\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.89475\n",
            "Epoch 98/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1214 - accuracy: 0.9698 - val_loss: 0.7817 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.89475\n",
            "Epoch 99/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1210 - accuracy: 0.9701 - val_loss: 0.7799 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.89475\n",
            "Epoch 100/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1186 - accuracy: 0.9692 - val_loss: 0.8086 - val_accuracy: 0.8915\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.89475\n",
            "Epoch 101/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1160 - accuracy: 0.9723 - val_loss: 0.8705 - val_accuracy: 0.8864\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.89475\n",
            "Epoch 102/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1169 - accuracy: 0.9726 - val_loss: 0.7581 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.89475\n",
            "Epoch 103/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1157 - accuracy: 0.9713 - val_loss: 0.8067 - val_accuracy: 0.8829\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.89475\n",
            "Epoch 104/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1171 - accuracy: 0.9725 - val_loss: 0.8146 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.89475\n",
            "Epoch 105/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1178 - accuracy: 0.9706 - val_loss: 0.8211 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.89475\n",
            "Epoch 106/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1185 - accuracy: 0.9706 - val_loss: 0.8021 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.89475\n",
            "Epoch 107/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1155 - accuracy: 0.9717 - val_loss: 0.8278 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.89475\n",
            "Epoch 108/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1193 - accuracy: 0.9708 - val_loss: 0.7756 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.89475\n",
            "Epoch 109/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1137 - accuracy: 0.9737 - val_loss: 0.8252 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.89475\n",
            "Epoch 110/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1191 - accuracy: 0.9720 - val_loss: 0.8399 - val_accuracy: 0.8908\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.89475\n",
            "Epoch 111/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1130 - accuracy: 0.9738 - val_loss: 0.7576 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.89475\n",
            "Epoch 112/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1177 - accuracy: 0.9718 - val_loss: 0.9638 - val_accuracy: 0.8817\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.89475\n",
            "Epoch 113/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1164 - accuracy: 0.9725 - val_loss: 0.8103 - val_accuracy: 0.8789\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.89475\n",
            "Epoch 114/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1143 - accuracy: 0.9737 - val_loss: 0.7806 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.89475\n",
            "Epoch 115/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1163 - accuracy: 0.9736 - val_loss: 0.8687 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.89475\n",
            "Epoch 116/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1159 - accuracy: 0.9728 - val_loss: 0.8180 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.89475\n",
            "Epoch 117/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1127 - accuracy: 0.9730 - val_loss: 0.9564 - val_accuracy: 0.8755\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.89475\n",
            "Epoch 118/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1130 - accuracy: 0.9730 - val_loss: 0.8649 - val_accuracy: 0.8797\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.89475\n",
            "Epoch 119/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1130 - accuracy: 0.9729 - val_loss: 0.8387 - val_accuracy: 0.8844\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.89475\n",
            "Epoch 120/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1185 - accuracy: 0.9712 - val_loss: 0.8803 - val_accuracy: 0.8829\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.89475\n",
            "Epoch 121/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1128 - accuracy: 0.9738 - val_loss: 0.9069 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.89475\n",
            "Epoch 122/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1145 - accuracy: 0.9733 - val_loss: 0.9067 - val_accuracy: 0.8814\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.89475\n",
            "Epoch 123/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1138 - accuracy: 0.9742 - val_loss: 0.8786 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.89475\n",
            "Epoch 124/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1121 - accuracy: 0.9748 - val_loss: 0.8722 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.89475\n",
            "Epoch 125/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1105 - accuracy: 0.9755 - val_loss: 0.8265 - val_accuracy: 0.8864\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.89475\n",
            "Epoch 126/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1104 - accuracy: 0.9749 - val_loss: 0.8304 - val_accuracy: 0.8860\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.89475\n",
            "Epoch 127/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1124 - accuracy: 0.9739 - val_loss: 0.8486 - val_accuracy: 0.8831\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.89475\n",
            "Epoch 128/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1100 - accuracy: 0.9754 - val_loss: 0.8013 - val_accuracy: 0.8849\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.89475\n",
            "Epoch 129/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1100 - accuracy: 0.9749 - val_loss: 0.8862 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.89475\n",
            "Epoch 130/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1053 - accuracy: 0.9758 - val_loss: 0.9508 - val_accuracy: 0.8734\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.89475\n",
            "Epoch 131/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1094 - accuracy: 0.9762 - val_loss: 0.8466 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.89475\n",
            "Epoch 132/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1094 - accuracy: 0.9755 - val_loss: 0.8287 - val_accuracy: 0.8865\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.89475\n",
            "Epoch 133/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1093 - accuracy: 0.9752 - val_loss: 0.8281 - val_accuracy: 0.8872\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.89475\n",
            "Epoch 134/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1120 - accuracy: 0.9748 - val_loss: 0.8575 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.89475\n",
            "Epoch 135/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1101 - accuracy: 0.9750 - val_loss: 0.9167 - val_accuracy: 0.8855\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.89475\n",
            "Epoch 136/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1078 - accuracy: 0.9754 - val_loss: 0.9070 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.89475\n",
            "Epoch 137/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1091 - accuracy: 0.9759 - val_loss: 0.7749 - val_accuracy: 0.8854\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.89475\n",
            "Epoch 138/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1051 - accuracy: 0.9762 - val_loss: 0.8353 - val_accuracy: 0.8844\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.89475\n",
            "Epoch 139/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1034 - accuracy: 0.9778 - val_loss: 0.8653 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.89475\n",
            "Epoch 140/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1078 - accuracy: 0.9768 - val_loss: 1.0180 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.89475\n",
            "Epoch 141/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1083 - accuracy: 0.9764 - val_loss: 0.8185 - val_accuracy: 0.8767\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.89475\n",
            "Epoch 142/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1071 - accuracy: 0.9767 - val_loss: 0.8948 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.89475\n",
            "Epoch 143/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1088 - accuracy: 0.9755 - val_loss: 0.9582 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.89475\n",
            "Epoch 144/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1059 - accuracy: 0.9772 - val_loss: 1.0503 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.89475\n",
            "Epoch 145/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1099 - accuracy: 0.9768 - val_loss: 0.9534 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.89475\n",
            "Epoch 146/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1034 - accuracy: 0.9785 - val_loss: 0.8850 - val_accuracy: 0.8886\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.89475\n",
            "Epoch 147/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1066 - accuracy: 0.9777 - val_loss: 0.8642 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.89475\n",
            "Epoch 148/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1038 - accuracy: 0.9764 - val_loss: 0.8918 - val_accuracy: 0.8857\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.89475\n",
            "Epoch 149/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1070 - accuracy: 0.9774 - val_loss: 0.8841 - val_accuracy: 0.8904\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.89475\n",
            "Epoch 150/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1073 - accuracy: 0.9776 - val_loss: 0.9132 - val_accuracy: 0.8873\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.89475\n",
            "Epoch 151/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.9772 - val_loss: 0.8727 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.89475\n",
            "Epoch 152/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1037 - accuracy: 0.9788 - val_loss: 0.8260 - val_accuracy: 0.8876\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.89475\n",
            "Epoch 153/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1037 - accuracy: 0.9773 - val_loss: 1.0347 - val_accuracy: 0.8778\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.89475\n",
            "Epoch 154/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1140 - accuracy: 0.9747 - val_loss: 0.9901 - val_accuracy: 0.8869\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.89475\n",
            "Epoch 155/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1035 - accuracy: 0.9786 - val_loss: 0.8442 - val_accuracy: 0.8871\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.89475\n",
            "Epoch 156/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1050 - accuracy: 0.9787 - val_loss: 1.0245 - val_accuracy: 0.8734\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.89475\n",
            "Epoch 157/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1100 - accuracy: 0.9766 - val_loss: 0.8771 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.89475\n",
            "Epoch 158/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1020 - accuracy: 0.9791 - val_loss: 0.8829 - val_accuracy: 0.8909\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.89475\n",
            "Epoch 159/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1014 - accuracy: 0.9794 - val_loss: 1.1487 - val_accuracy: 0.8708\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.89475\n",
            "Epoch 160/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1094 - accuracy: 0.9759 - val_loss: 0.8696 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.89475\n",
            "Epoch 161/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1009 - accuracy: 0.9783 - val_loss: 0.8764 - val_accuracy: 0.8901\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.89475\n",
            "Epoch 162/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0997 - accuracy: 0.9785 - val_loss: 0.9283 - val_accuracy: 0.8791\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.89475\n",
            "Epoch 163/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1017 - accuracy: 0.9786 - val_loss: 0.9313 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.89475\n",
            "Epoch 164/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0976 - accuracy: 0.9803 - val_loss: 0.8779 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.89475\n",
            "Epoch 165/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.9778 - val_loss: 0.9291 - val_accuracy: 0.8886\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.89475\n",
            "Epoch 166/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1000 - accuracy: 0.9794 - val_loss: 0.9719 - val_accuracy: 0.8866\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.89475\n",
            "Epoch 167/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1003 - accuracy: 0.9796 - val_loss: 0.9401 - val_accuracy: 0.8857\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.89475\n",
            "Epoch 168/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1044 - accuracy: 0.9795 - val_loss: 0.9349 - val_accuracy: 0.8880\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.89475\n",
            "Epoch 169/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1032 - accuracy: 0.9793 - val_loss: 0.9355 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.89475\n",
            "Epoch 170/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9787 - val_loss: 0.9913 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.89475\n",
            "Epoch 171/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1045 - accuracy: 0.9777 - val_loss: 1.1296 - val_accuracy: 0.8819\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.89475\n",
            "Epoch 172/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1003 - accuracy: 0.9792 - val_loss: 0.9377 - val_accuracy: 0.8899\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.89475\n",
            "Epoch 173/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1021 - accuracy: 0.9792 - val_loss: 1.0190 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.89475\n",
            "Epoch 174/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1065 - accuracy: 0.9782 - val_loss: 0.9411 - val_accuracy: 0.8880\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.89475\n",
            "Epoch 175/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1025 - accuracy: 0.9786 - val_loss: 0.9639 - val_accuracy: 0.8809\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.89475\n",
            "Epoch 176/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0979 - accuracy: 0.9812 - val_loss: 0.8273 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.89475\n",
            "Epoch 177/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9784 - val_loss: 0.9974 - val_accuracy: 0.8888\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.89475\n",
            "Epoch 178/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1012 - accuracy: 0.9805 - val_loss: 0.9466 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.89475\n",
            "Epoch 179/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1035 - accuracy: 0.9797 - val_loss: 0.9454 - val_accuracy: 0.8849\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.89475\n",
            "Epoch 180/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9787 - val_loss: 1.0554 - val_accuracy: 0.8829\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.89475\n",
            "Epoch 181/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1057 - accuracy: 0.9789 - val_loss: 0.9818 - val_accuracy: 0.8865\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.89475\n",
            "Epoch 182/500\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1003 - accuracy: 0.9795 - val_loss: 0.8732 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.89475\n",
            "Epoch 00182: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "fRJpuAzsNXRY",
        "outputId": "9c4ec7a7-6c40-4064-ad6b-1acf5c1832c3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "epochs = range(1, len(Hist_L2.history['loss'])+1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, Hist_L2.history['loss'])\n",
        "plt.plot(epochs, Hist_L2.history['val_loss'])\n",
        "plt.legend(['Train loss','Test loss'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, Hist_L2.history['accuracy'])\n",
        "plt.plot(epochs, Hist_L2.history['val_accuracy'])\n",
        "plt.legend(['accuracy','val_accuracy'])\n",
        "plt.grid()\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UpTKiAGOE4z",
        "outputId": "4e89a9c2-596b-4e29-f1a7-3f52c960d3cf"
      },
      "source": [
        "loss_L2, accuracy_L2 = L2.evaluate(X_test, y_test)\n",
        "print('Loss = {:.5f}'.format(loss_L2))\n",
        "print('Accuracy = {:.5f}'.format (accuracy_L2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9960 - accuracy: 0.8863\n",
            "Loss = 0.99603\n",
            "Accuracy = 0.88630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP4jlwCQtogg"
      },
      "source": [
        "# L2 + Batch Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tec88fHZxHLJ",
        "outputId": "d7cdaf47-f720-4329-cd08-2e43d8c15f65"
      },
      "source": [
        "L2_BN = models.Sequential()\n",
        "L2_BN.add(layers.Dense(512, input_shape=(28*28,),\n",
        "                       kernel_regularizer=regularizers.l2(0.00001)))\n",
        "L2_BN.add(layers.BatchNormalization())\n",
        "L2_BN.add(layers.Activation('relu'))\n",
        "L2_BN.add(layers.Dense(256,\n",
        "                       kernel_regularizer=regularizers.l2(0.00001)))\n",
        "L2_BN.add(layers.BatchNormalization())\n",
        "L2_BN.add(layers.Activation('relu'))\n",
        "L2_BN.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "L2_BN.summary()\n",
        "\n",
        "L2_BN.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 538,890\n",
            "Trainable params: 537,354\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMeEJq_iVcBl",
        "outputId": "3a808f10-2e1d-4fd1-9324-9691dba7bc0f"
      },
      "source": [
        "ex = EarlyStopping(monitor='val_accuracy', mode='max', patience=100, verbose = 1)\n",
        "mc = ModelCheckpoint('best-L2_BN.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "%time\n",
        "Hist_L2_BN = L2_BN.fit(X_train, y_train, epochs=500, batch_size=128, validation_split=0.2, callbacks=[ex, mc], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375/375 [==============================] - 4s 7ms/step - loss: 0.5669 - accuracy: 0.7990 - val_loss: 0.4579 - val_accuracy: 0.8398\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83983, saving model to best-DR_BN.h5\n",
            "Epoch 2/500\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3436 - accuracy: 0.8761 - val_loss: 0.3962 - val_accuracy: 0.8580\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.83983 to 0.85800, saving model to best-DR_BN.h5\n",
            "Epoch 3/500\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2864 - accuracy: 0.8977 - val_loss: 0.3918 - val_accuracy: 0.8637\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.85800 to 0.86367, saving model to best-DR_BN.h5\n",
            "Epoch 4/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2634 - accuracy: 0.9075 - val_loss: 0.4183 - val_accuracy: 0.8615\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.86367\n",
            "Epoch 5/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2431 - accuracy: 0.9140 - val_loss: 0.3558 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.86367 to 0.88158, saving model to best-DR_BN.h5\n",
            "Epoch 6/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2215 - accuracy: 0.9238 - val_loss: 0.4213 - val_accuracy: 0.8684\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.88158\n",
            "Epoch 7/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2041 - accuracy: 0.9295 - val_loss: 0.3468 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.88158 to 0.88825, saving model to best-DR_BN.h5\n",
            "Epoch 8/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1883 - accuracy: 0.9367 - val_loss: 0.4309 - val_accuracy: 0.8740\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.88825\n",
            "Epoch 9/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1831 - accuracy: 0.9378 - val_loss: 0.4362 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.88825\n",
            "Epoch 10/500\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1698 - accuracy: 0.9439 - val_loss: 0.3979 - val_accuracy: 0.8813\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.88825\n",
            "Epoch 11/500\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1571 - accuracy: 0.9501 - val_loss: 0.4186 - val_accuracy: 0.8787\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.88825\n",
            "Epoch 12/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1525 - accuracy: 0.9514 - val_loss: 0.4197 - val_accuracy: 0.8840\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.88825\n",
            "Epoch 13/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1444 - accuracy: 0.9539 - val_loss: 0.4255 - val_accuracy: 0.8833\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.88825\n",
            "Epoch 14/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1381 - accuracy: 0.9565 - val_loss: 0.4488 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.88825 to 0.88867, saving model to best-DR_BN.h5\n",
            "Epoch 15/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1289 - accuracy: 0.9611 - val_loss: 0.5383 - val_accuracy: 0.8688\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.88867\n",
            "Epoch 16/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1272 - accuracy: 0.9631 - val_loss: 0.5606 - val_accuracy: 0.8701\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.88867\n",
            "Epoch 17/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1207 - accuracy: 0.9648 - val_loss: 0.5645 - val_accuracy: 0.8686\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.88867\n",
            "Epoch 18/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1144 - accuracy: 0.9678 - val_loss: 0.5986 - val_accuracy: 0.8813\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.88867\n",
            "Epoch 19/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1085 - accuracy: 0.9696 - val_loss: 0.4861 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.88867\n",
            "Epoch 20/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1068 - accuracy: 0.9720 - val_loss: 0.5486 - val_accuracy: 0.8783\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.88867\n",
            "Epoch 21/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1079 - accuracy: 0.9721 - val_loss: 0.6265 - val_accuracy: 0.8728\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.88867\n",
            "Epoch 22/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1014 - accuracy: 0.9753 - val_loss: 0.6151 - val_accuracy: 0.8715\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.88867\n",
            "Epoch 23/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1023 - accuracy: 0.9743 - val_loss: 0.5363 - val_accuracy: 0.8860\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.88867\n",
            "Epoch 24/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0988 - accuracy: 0.9754 - val_loss: 0.6313 - val_accuracy: 0.8823\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.88867\n",
            "Epoch 25/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0945 - accuracy: 0.9775 - val_loss: 0.7647 - val_accuracy: 0.8639\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.88867\n",
            "Epoch 26/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0959 - accuracy: 0.9775 - val_loss: 0.7074 - val_accuracy: 0.8669\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.88867\n",
            "Epoch 27/500\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0935 - accuracy: 0.9798 - val_loss: 0.6709 - val_accuracy: 0.8650\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88867\n",
            "Epoch 28/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0897 - accuracy: 0.9800 - val_loss: 0.6184 - val_accuracy: 0.8790\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88867\n",
            "Epoch 29/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0890 - accuracy: 0.9810 - val_loss: 0.8203 - val_accuracy: 0.8718\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88867\n",
            "Epoch 30/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0912 - accuracy: 0.9801 - val_loss: 0.6278 - val_accuracy: 0.8846\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88867\n",
            "Epoch 31/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0854 - accuracy: 0.9825 - val_loss: 0.7014 - val_accuracy: 0.8802\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88867\n",
            "Epoch 32/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0865 - accuracy: 0.9827 - val_loss: 0.7312 - val_accuracy: 0.8763\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88867\n",
            "Epoch 33/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0883 - accuracy: 0.9828 - val_loss: 0.6791 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88867\n",
            "Epoch 34/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0838 - accuracy: 0.9840 - val_loss: 0.8186 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88867\n",
            "Epoch 35/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0831 - accuracy: 0.9840 - val_loss: 0.7052 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88867\n",
            "Epoch 36/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0836 - accuracy: 0.9840 - val_loss: 0.7228 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88867\n",
            "Epoch 37/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0825 - accuracy: 0.9850 - val_loss: 0.9378 - val_accuracy: 0.8671\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88867\n",
            "Epoch 38/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0828 - accuracy: 0.9846 - val_loss: 0.7017 - val_accuracy: 0.8790\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88867\n",
            "Epoch 39/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0817 - accuracy: 0.9856 - val_loss: 0.6958 - val_accuracy: 0.8798\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88867\n",
            "Epoch 40/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0833 - accuracy: 0.9854 - val_loss: 0.7467 - val_accuracy: 0.8786\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88867\n",
            "Epoch 41/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0796 - accuracy: 0.9861 - val_loss: 0.7999 - val_accuracy: 0.8780\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88867\n",
            "Epoch 42/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0840 - accuracy: 0.9848 - val_loss: 0.7112 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88867\n",
            "Epoch 43/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0804 - accuracy: 0.9869 - val_loss: 0.7385 - val_accuracy: 0.8837\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88867\n",
            "Epoch 44/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0813 - accuracy: 0.9877 - val_loss: 0.7357 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88867\n",
            "Epoch 45/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0803 - accuracy: 0.9870 - val_loss: 0.8854 - val_accuracy: 0.8662\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88867\n",
            "Epoch 46/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0815 - accuracy: 0.9867 - val_loss: 0.8260 - val_accuracy: 0.8781\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88867\n",
            "Epoch 47/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0771 - accuracy: 0.9877 - val_loss: 0.9760 - val_accuracy: 0.8597\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88867\n",
            "Epoch 48/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0797 - accuracy: 0.9874 - val_loss: 0.8700 - val_accuracy: 0.8699\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88867\n",
            "Epoch 49/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0781 - accuracy: 0.9881 - val_loss: 0.8012 - val_accuracy: 0.8854\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88867\n",
            "Epoch 50/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0819 - accuracy: 0.9863 - val_loss: 0.7986 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88867\n",
            "Epoch 51/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0802 - accuracy: 0.9866 - val_loss: 0.8526 - val_accuracy: 0.8789\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.88867\n",
            "Epoch 52/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0772 - accuracy: 0.9886 - val_loss: 0.7498 - val_accuracy: 0.8886\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.88867\n",
            "Epoch 53/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0771 - accuracy: 0.9882 - val_loss: 1.0373 - val_accuracy: 0.8817\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.88867\n",
            "Epoch 54/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0810 - accuracy: 0.9873 - val_loss: 0.7123 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.88867\n",
            "Epoch 55/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0779 - accuracy: 0.9885 - val_loss: 0.8396 - val_accuracy: 0.8826\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.88867\n",
            "Epoch 56/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0753 - accuracy: 0.9894 - val_loss: 0.7616 - val_accuracy: 0.8896\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.88867 to 0.88958, saving model to best-DR_BN.h5\n",
            "Epoch 57/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0767 - accuracy: 0.9880 - val_loss: 0.8454 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.88958 to 0.89133, saving model to best-DR_BN.h5\n",
            "Epoch 58/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0759 - accuracy: 0.9889 - val_loss: 0.8622 - val_accuracy: 0.8829\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89133\n",
            "Epoch 59/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0757 - accuracy: 0.9891 - val_loss: 0.8723 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89133\n",
            "Epoch 60/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0775 - accuracy: 0.9895 - val_loss: 0.8413 - val_accuracy: 0.8773\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89133\n",
            "Epoch 61/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0784 - accuracy: 0.9882 - val_loss: 0.9518 - val_accuracy: 0.8795\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89133\n",
            "Epoch 62/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0764 - accuracy: 0.9889 - val_loss: 0.9652 - val_accuracy: 0.8733\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89133\n",
            "Epoch 63/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0755 - accuracy: 0.9892 - val_loss: 0.8976 - val_accuracy: 0.8839\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89133\n",
            "Epoch 64/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0765 - accuracy: 0.9892 - val_loss: 0.9084 - val_accuracy: 0.8780\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89133\n",
            "Epoch 65/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0763 - accuracy: 0.9895 - val_loss: 0.8757 - val_accuracy: 0.8712\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89133\n",
            "Epoch 66/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0773 - accuracy: 0.9891 - val_loss: 0.9982 - val_accuracy: 0.8764\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89133\n",
            "Epoch 67/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0765 - accuracy: 0.9892 - val_loss: 0.9445 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89133\n",
            "Epoch 68/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0756 - accuracy: 0.9896 - val_loss: 1.1239 - val_accuracy: 0.8641\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89133\n",
            "Epoch 69/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0755 - accuracy: 0.9894 - val_loss: 0.9225 - val_accuracy: 0.8830\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89133\n",
            "Epoch 70/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0741 - accuracy: 0.9895 - val_loss: 1.0302 - val_accuracy: 0.8758\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89133\n",
            "Epoch 71/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0741 - accuracy: 0.9891 - val_loss: 0.9642 - val_accuracy: 0.8643\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89133\n",
            "Epoch 72/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0768 - accuracy: 0.9895 - val_loss: 0.8965 - val_accuracy: 0.8865\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.89133\n",
            "Epoch 73/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0701 - accuracy: 0.9917 - val_loss: 0.9441 - val_accuracy: 0.8775\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.89133\n",
            "Epoch 74/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0722 - accuracy: 0.9909 - val_loss: 0.8787 - val_accuracy: 0.8859\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.89133\n",
            "Epoch 75/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0762 - accuracy: 0.9898 - val_loss: 0.9075 - val_accuracy: 0.8853\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.89133\n",
            "Epoch 76/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0743 - accuracy: 0.9900 - val_loss: 0.9897 - val_accuracy: 0.8861\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.89133\n",
            "Epoch 77/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0726 - accuracy: 0.9905 - val_loss: 1.0601 - val_accuracy: 0.8799\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.89133\n",
            "Epoch 78/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0719 - accuracy: 0.9912 - val_loss: 0.9620 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.89133\n",
            "Epoch 79/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0716 - accuracy: 0.9912 - val_loss: 0.8685 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.89133\n",
            "Epoch 80/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0735 - accuracy: 0.9909 - val_loss: 0.9881 - val_accuracy: 0.8738\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.89133\n",
            "Epoch 81/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0749 - accuracy: 0.9896 - val_loss: 0.8922 - val_accuracy: 0.8857\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.89133\n",
            "Epoch 82/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0730 - accuracy: 0.9908 - val_loss: 0.9893 - val_accuracy: 0.8827\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.89133\n",
            "Epoch 83/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0735 - accuracy: 0.9908 - val_loss: 0.9619 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.89133\n",
            "Epoch 84/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0747 - accuracy: 0.9908 - val_loss: 0.9280 - val_accuracy: 0.8858\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.89133\n",
            "Epoch 85/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0750 - accuracy: 0.9909 - val_loss: 0.9766 - val_accuracy: 0.8810\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.89133\n",
            "Epoch 86/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0740 - accuracy: 0.9916 - val_loss: 1.0316 - val_accuracy: 0.8674\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.89133\n",
            "Epoch 87/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0723 - accuracy: 0.9914 - val_loss: 0.9584 - val_accuracy: 0.8855\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.89133\n",
            "Epoch 88/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0733 - accuracy: 0.9904 - val_loss: 0.8642 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.89133\n",
            "Epoch 89/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0719 - accuracy: 0.9908 - val_loss: 0.9480 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.89133\n",
            "Epoch 90/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0734 - accuracy: 0.9915 - val_loss: 1.0380 - val_accuracy: 0.8868\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.89133\n",
            "Epoch 91/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0708 - accuracy: 0.9917 - val_loss: 0.9186 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.89133\n",
            "Epoch 92/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0730 - accuracy: 0.9913 - val_loss: 1.0821 - val_accuracy: 0.8773\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.89133\n",
            "Epoch 93/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0723 - accuracy: 0.9912 - val_loss: 0.9456 - val_accuracy: 0.8853\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.89133\n",
            "Epoch 94/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0713 - accuracy: 0.9914 - val_loss: 1.1113 - val_accuracy: 0.8721\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.89133\n",
            "Epoch 95/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0694 - accuracy: 0.9923 - val_loss: 0.9533 - val_accuracy: 0.8831\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.89133\n",
            "Epoch 96/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0714 - accuracy: 0.9911 - val_loss: 0.9878 - val_accuracy: 0.8871\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.89133\n",
            "Epoch 97/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0716 - accuracy: 0.9918 - val_loss: 0.9940 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.89133\n",
            "Epoch 98/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0721 - accuracy: 0.9916 - val_loss: 1.2867 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.89133\n",
            "Epoch 99/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0700 - accuracy: 0.9916 - val_loss: 0.9419 - val_accuracy: 0.8802\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.89133\n",
            "Epoch 100/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0708 - accuracy: 0.9916 - val_loss: 1.1902 - val_accuracy: 0.8713\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.89133\n",
            "Epoch 101/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0698 - accuracy: 0.9920 - val_loss: 0.9357 - val_accuracy: 0.8904\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.89133\n",
            "Epoch 102/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0694 - accuracy: 0.9919 - val_loss: 1.0839 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.89133\n",
            "Epoch 103/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0703 - accuracy: 0.9915 - val_loss: 1.1552 - val_accuracy: 0.8753\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.89133\n",
            "Epoch 104/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0702 - accuracy: 0.9922 - val_loss: 0.9891 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.89133\n",
            "Epoch 105/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0687 - accuracy: 0.9924 - val_loss: 0.9940 - val_accuracy: 0.8826\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.89133\n",
            "Epoch 106/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0704 - accuracy: 0.9921 - val_loss: 1.0112 - val_accuracy: 0.8845\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.89133\n",
            "Epoch 107/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0747 - accuracy: 0.9905 - val_loss: 0.9888 - val_accuracy: 0.8779\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.89133\n",
            "Epoch 108/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0743 - accuracy: 0.9909 - val_loss: 1.1012 - val_accuracy: 0.8737\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.89133\n",
            "Epoch 109/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0688 - accuracy: 0.9917 - val_loss: 1.2069 - val_accuracy: 0.8665\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.89133\n",
            "Epoch 110/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0719 - accuracy: 0.9912 - val_loss: 0.9486 - val_accuracy: 0.8820\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.89133\n",
            "Epoch 111/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0678 - accuracy: 0.9925 - val_loss: 1.1186 - val_accuracy: 0.8774\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.89133\n",
            "Epoch 112/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0736 - accuracy: 0.9916 - val_loss: 1.0476 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.89133\n",
            "Epoch 113/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0710 - accuracy: 0.9915 - val_loss: 1.1401 - val_accuracy: 0.8725\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.89133\n",
            "Epoch 114/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0685 - accuracy: 0.9930 - val_loss: 1.1476 - val_accuracy: 0.8699\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.89133\n",
            "Epoch 115/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0719 - accuracy: 0.9910 - val_loss: 0.8963 - val_accuracy: 0.8880\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.89133\n",
            "Epoch 116/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0699 - accuracy: 0.9924 - val_loss: 1.0469 - val_accuracy: 0.8888\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.89133\n",
            "Epoch 117/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0696 - accuracy: 0.9925 - val_loss: 1.0092 - val_accuracy: 0.8741\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.89133\n",
            "Epoch 118/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0684 - accuracy: 0.9926 - val_loss: 1.0073 - val_accuracy: 0.8801\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.89133\n",
            "Epoch 119/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0705 - accuracy: 0.9915 - val_loss: 1.1065 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.89133\n",
            "Epoch 120/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0707 - accuracy: 0.9911 - val_loss: 1.0346 - val_accuracy: 0.8837\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.89133\n",
            "Epoch 121/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0677 - accuracy: 0.9919 - val_loss: 1.1690 - val_accuracy: 0.8763\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.89133\n",
            "Epoch 122/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0725 - accuracy: 0.9917 - val_loss: 1.1495 - val_accuracy: 0.8776\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.89133\n",
            "Epoch 123/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0720 - accuracy: 0.9917 - val_loss: 1.0812 - val_accuracy: 0.8758\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.89133\n",
            "Epoch 124/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0702 - accuracy: 0.9920 - val_loss: 0.9382 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.89133\n",
            "Epoch 125/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0684 - accuracy: 0.9926 - val_loss: 1.0672 - val_accuracy: 0.8849\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.89133\n",
            "Epoch 126/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0666 - accuracy: 0.9929 - val_loss: 1.0400 - val_accuracy: 0.8853\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.89133\n",
            "Epoch 127/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0710 - accuracy: 0.9915 - val_loss: 0.9786 - val_accuracy: 0.8809\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.89133\n",
            "Epoch 128/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0675 - accuracy: 0.9924 - val_loss: 1.1590 - val_accuracy: 0.8781\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.89133\n",
            "Epoch 129/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0656 - accuracy: 0.9931 - val_loss: 0.9914 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.89133\n",
            "Epoch 130/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0656 - accuracy: 0.9934 - val_loss: 1.0720 - val_accuracy: 0.8839\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.89133\n",
            "Epoch 131/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0669 - accuracy: 0.9920 - val_loss: 1.0894 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.89133\n",
            "Epoch 132/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0694 - accuracy: 0.9919 - val_loss: 0.9285 - val_accuracy: 0.8898\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.89133\n",
            "Epoch 133/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0661 - accuracy: 0.9933 - val_loss: 1.0191 - val_accuracy: 0.8859\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.89133\n",
            "Epoch 134/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0694 - accuracy: 0.9919 - val_loss: 1.0070 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.89133\n",
            "Epoch 135/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0673 - accuracy: 0.9921 - val_loss: 1.0056 - val_accuracy: 0.8881\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.89133\n",
            "Epoch 136/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0685 - accuracy: 0.9917 - val_loss: 1.3443 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.89133\n",
            "Epoch 137/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0703 - accuracy: 0.9922 - val_loss: 1.2015 - val_accuracy: 0.8837\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.89133\n",
            "Epoch 138/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0703 - accuracy: 0.9917 - val_loss: 1.1176 - val_accuracy: 0.8801\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.89133\n",
            "Epoch 139/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9926 - val_loss: 1.0252 - val_accuracy: 0.8840\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.89133\n",
            "Epoch 140/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0667 - accuracy: 0.9931 - val_loss: 1.2501 - val_accuracy: 0.8746\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.89133\n",
            "Epoch 141/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0668 - accuracy: 0.9927 - val_loss: 1.2466 - val_accuracy: 0.8675\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.89133\n",
            "Epoch 142/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0698 - accuracy: 0.9919 - val_loss: 1.0182 - val_accuracy: 0.8893\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.89133\n",
            "Epoch 143/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0675 - accuracy: 0.9921 - val_loss: 1.0575 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.89133\n",
            "Epoch 144/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0720 - accuracy: 0.9917 - val_loss: 1.0817 - val_accuracy: 0.8798\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.89133\n",
            "Epoch 145/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0711 - accuracy: 0.9912 - val_loss: 1.3460 - val_accuracy: 0.8767\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.89133\n",
            "Epoch 146/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0720 - accuracy: 0.9916 - val_loss: 0.9274 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.89133\n",
            "Epoch 147/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0692 - accuracy: 0.9923 - val_loss: 1.0974 - val_accuracy: 0.8810\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.89133\n",
            "Epoch 148/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0687 - accuracy: 0.9922 - val_loss: 1.1055 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.89133\n",
            "Epoch 149/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0670 - accuracy: 0.9923 - val_loss: 1.1021 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.89133\n",
            "Epoch 150/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0672 - accuracy: 0.9933 - val_loss: 1.1739 - val_accuracy: 0.8757\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.89133\n",
            "Epoch 151/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0645 - accuracy: 0.9929 - val_loss: 1.0339 - val_accuracy: 0.8775\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.89133\n",
            "Epoch 152/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0703 - accuracy: 0.9917 - val_loss: 1.0889 - val_accuracy: 0.8831\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.89133\n",
            "Epoch 153/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0696 - accuracy: 0.9922 - val_loss: 1.0133 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.89133\n",
            "Epoch 154/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0690 - accuracy: 0.9920 - val_loss: 1.0469 - val_accuracy: 0.8869\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.89133\n",
            "Epoch 155/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0685 - accuracy: 0.9935 - val_loss: 1.1198 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.89133\n",
            "Epoch 156/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0670 - accuracy: 0.9935 - val_loss: 1.0988 - val_accuracy: 0.8821\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.89133\n",
            "Epoch 157/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0672 - accuracy: 0.9926 - val_loss: 1.1010 - val_accuracy: 0.8823\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.89133\n",
            "Epoch 00157: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "kB7leuyJ-2gG",
        "outputId": "8df3f61e-5221-4a3c-c762-3f24a2e5b5ba"
      },
      "source": [
        "epochs = range(1, len(Hist_L2_BN.history['loss'])+1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, Hist_L2_BN.history['loss'])\n",
        "plt.plot(epochs, Hist_L2_BN.history['val_loss'])\n",
        "plt.legend(['Train loss','Test loss'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, Hist_L2_BN.history['accuracy'])\n",
        "plt.plot(epochs, Hist_L2_BN.history['val_accuracy'])\n",
        "plt.legend(['accuracy','val_accuracy'])\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCMVqV9t-6Ui",
        "outputId": "09d0a4ac-0bf4-4a52-cd46-652d617f18f8"
      },
      "source": [
        "loss_L2_BN, accuracy_L2_BN = L2_BN.evaluate(X_test, y_test)\n",
        "print('Loss = {:.5f}'.format(loss_L2_BN))\n",
        "print('Accuracy = {:.5f}'.format (accuracy_L2_BN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1495 - accuracy: 0.8781\n",
            "Loss = 1.14954\n",
            "Accuracy = 0.87810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKDUHyLOtvr6"
      },
      "source": [
        "# Dropout + Batch Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4Jfsag7_D8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53afb4f-ee39-46dc-8698-15bae3a6e2bc"
      },
      "source": [
        "DR_BN = models.Sequential()\n",
        "\n",
        "DR_BN.add(layers.Dense(512, input_shape=(28*28,)))\n",
        "DR_BN.add(layers.BatchNormalization())\n",
        "DR_BN.add(layers.Activation('relu'))\n",
        "DR_BN.add(layers.Dropout(0.4))\n",
        "DR_BN.add(layers.Dense(256))\n",
        "DR_BN.add(layers.BatchNormalization())\n",
        "\n",
        "DR_BN.add(layers.Activation('relu'))\n",
        "DR_BN.add(layers.Dropout(0.4))\n",
        "DR_BN.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "DR_BN.summary()\n",
        "\n",
        "DR_BN.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 538,890\n",
            "Trainable params: 537,354\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpP5xF0gQ2Hx",
        "outputId": "0dd1a51e-e05f-4530-9e73-41c3712fa762"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=100, verbose = 1)\n",
        "mc = ModelCheckpoint('best-DR_BN.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "%time\n",
        "Hist_DR_BN = DR_BN.fit(X_train, y_train, epochs=500, batch_size=128, validation_split=0.2, callbacks=[es, mc], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n",
            "Epoch 1/500\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 0.6970 - accuracy: 0.7589 - val_loss: 0.4778 - val_accuracy: 0.8348\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83483, saving model to best-DR_BN.h5\n",
            "Epoch 2/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.4238 - accuracy: 0.8473 - val_loss: 0.4133 - val_accuracy: 0.8481\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.83483 to 0.84808, saving model to best-DR_BN.h5\n",
            "Epoch 3/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3814 - accuracy: 0.8605 - val_loss: 0.4075 - val_accuracy: 0.8597\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.84808 to 0.85975, saving model to best-DR_BN.h5\n",
            "Epoch 4/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3532 - accuracy: 0.8711 - val_loss: 0.3583 - val_accuracy: 0.8735\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.85975 to 0.87350, saving model to best-DR_BN.h5\n",
            "Epoch 5/500\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.3319 - accuracy: 0.8778 - val_loss: 0.4152 - val_accuracy: 0.8612\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.87350\n",
            "Epoch 6/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3270 - accuracy: 0.8800 - val_loss: 0.3844 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.87350\n",
            "Epoch 7/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3124 - accuracy: 0.8886 - val_loss: 0.3262 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.87350 to 0.88417, saving model to best-DR_BN.h5\n",
            "Epoch 8/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3069 - accuracy: 0.8894 - val_loss: 0.3495 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.88417\n",
            "Epoch 9/500\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2957 - accuracy: 0.8941 - val_loss: 0.3392 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.88417 to 0.88750, saving model to best-DR_BN.h5\n",
            "Epoch 10/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2897 - accuracy: 0.8951 - val_loss: 0.3608 - val_accuracy: 0.8801\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.88750\n",
            "Epoch 11/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2864 - accuracy: 0.8969 - val_loss: 0.3376 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.88750\n",
            "Epoch 12/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2698 - accuracy: 0.9008 - val_loss: 0.3655 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.88750\n",
            "Epoch 13/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2709 - accuracy: 0.9006 - val_loss: 0.3974 - val_accuracy: 0.8833\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.88750\n",
            "Epoch 14/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2548 - accuracy: 0.9081 - val_loss: 0.3246 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.88750 to 0.88925, saving model to best-DR_BN.h5\n",
            "Epoch 15/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2577 - accuracy: 0.9074 - val_loss: 0.3711 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.88925\n",
            "Epoch 16/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2507 - accuracy: 0.9100 - val_loss: 0.3758 - val_accuracy: 0.8833\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.88925\n",
            "Epoch 17/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2494 - accuracy: 0.9085 - val_loss: 0.3571 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.88925\n",
            "Epoch 18/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2336 - accuracy: 0.9135 - val_loss: 0.3240 - val_accuracy: 0.8946\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.88925 to 0.89458, saving model to best-DR_BN.h5\n",
            "Epoch 19/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2332 - accuracy: 0.9139 - val_loss: 0.3718 - val_accuracy: 0.8873\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.89458\n",
            "Epoch 20/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2323 - accuracy: 0.9157 - val_loss: 0.3513 - val_accuracy: 0.8888\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89458\n",
            "Epoch 21/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2282 - accuracy: 0.9176 - val_loss: 0.3715 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.89458\n",
            "Epoch 22/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2266 - accuracy: 0.9193 - val_loss: 0.3621 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89458\n",
            "Epoch 23/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2181 - accuracy: 0.9203 - val_loss: 0.3647 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89458\n",
            "Epoch 24/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2159 - accuracy: 0.9242 - val_loss: 0.3871 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89458\n",
            "Epoch 25/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2129 - accuracy: 0.9241 - val_loss: 0.3942 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89458\n",
            "Epoch 26/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2168 - accuracy: 0.9234 - val_loss: 0.3510 - val_accuracy: 0.8915\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89458\n",
            "Epoch 27/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2051 - accuracy: 0.9269 - val_loss: 0.3711 - val_accuracy: 0.8918\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89458\n",
            "Epoch 28/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2057 - accuracy: 0.9266 - val_loss: 0.3589 - val_accuracy: 0.8911\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89458\n",
            "Epoch 29/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1979 - accuracy: 0.9293 - val_loss: 0.4132 - val_accuracy: 0.8903\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89458\n",
            "Epoch 30/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2022 - accuracy: 0.9269 - val_loss: 0.3829 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89458\n",
            "Epoch 31/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1959 - accuracy: 0.9295 - val_loss: 0.3656 - val_accuracy: 0.8952\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.89458 to 0.89517, saving model to best-DR_BN.h5\n",
            "Epoch 32/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1882 - accuracy: 0.9324 - val_loss: 0.4313 - val_accuracy: 0.8798\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89517\n",
            "Epoch 33/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1925 - accuracy: 0.9300 - val_loss: 0.4128 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89517\n",
            "Epoch 34/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1888 - accuracy: 0.9320 - val_loss: 0.4134 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89517\n",
            "Epoch 35/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1870 - accuracy: 0.9316 - val_loss: 0.4084 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.89517 to 0.89708, saving model to best-DR_BN.h5\n",
            "Epoch 36/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1849 - accuracy: 0.9334 - val_loss: 0.4156 - val_accuracy: 0.8903\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89708\n",
            "Epoch 37/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1850 - accuracy: 0.9330 - val_loss: 0.4311 - val_accuracy: 0.8915\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89708\n",
            "Epoch 38/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1746 - accuracy: 0.9385 - val_loss: 0.3856 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89708\n",
            "Epoch 39/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1761 - accuracy: 0.9356 - val_loss: 0.3931 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89708\n",
            "Epoch 40/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1783 - accuracy: 0.9366 - val_loss: 0.4577 - val_accuracy: 0.8844\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89708\n",
            "Epoch 41/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1738 - accuracy: 0.9379 - val_loss: 0.4446 - val_accuracy: 0.8911\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89708\n",
            "Epoch 42/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1764 - accuracy: 0.9365 - val_loss: 0.4649 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89708\n",
            "Epoch 43/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1658 - accuracy: 0.9407 - val_loss: 0.3959 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89708\n",
            "Epoch 44/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1706 - accuracy: 0.9401 - val_loss: 0.3791 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89708\n",
            "Epoch 45/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1678 - accuracy: 0.9394 - val_loss: 0.4482 - val_accuracy: 0.8873\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89708\n",
            "Epoch 46/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1621 - accuracy: 0.9423 - val_loss: 0.4816 - val_accuracy: 0.8854\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89708\n",
            "Epoch 47/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1690 - accuracy: 0.9409 - val_loss: 0.4912 - val_accuracy: 0.8788\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89708\n",
            "Epoch 48/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1658 - accuracy: 0.9405 - val_loss: 0.3991 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89708\n",
            "Epoch 49/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1653 - accuracy: 0.9425 - val_loss: 0.4103 - val_accuracy: 0.8953\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89708\n",
            "Epoch 50/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1567 - accuracy: 0.9427 - val_loss: 0.4144 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89708\n",
            "Epoch 51/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1571 - accuracy: 0.9428 - val_loss: 0.4306 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89708\n",
            "Epoch 52/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1566 - accuracy: 0.9443 - val_loss: 0.5123 - val_accuracy: 0.8944\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89708\n",
            "Epoch 53/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1561 - accuracy: 0.9441 - val_loss: 0.4407 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89708\n",
            "Epoch 54/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1534 - accuracy: 0.9462 - val_loss: 0.4827 - val_accuracy: 0.8980\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.89708 to 0.89800, saving model to best-DR_BN.h5\n",
            "Epoch 55/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1520 - accuracy: 0.9475 - val_loss: 0.5057 - val_accuracy: 0.8950\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89800\n",
            "Epoch 56/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1532 - accuracy: 0.9459 - val_loss: 0.4517 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89800\n",
            "Epoch 57/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1524 - accuracy: 0.9465 - val_loss: 0.4561 - val_accuracy: 0.8944\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89800\n",
            "Epoch 58/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1449 - accuracy: 0.9490 - val_loss: 0.4753 - val_accuracy: 0.8898\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89800\n",
            "Epoch 59/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1469 - accuracy: 0.9499 - val_loss: 0.4919 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89800\n",
            "Epoch 60/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1439 - accuracy: 0.9495 - val_loss: 0.4875 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89800\n",
            "Epoch 61/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1450 - accuracy: 0.9495 - val_loss: 0.4484 - val_accuracy: 0.8943\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89800\n",
            "Epoch 62/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1472 - accuracy: 0.9477 - val_loss: 0.4855 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89800\n",
            "Epoch 63/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1424 - accuracy: 0.9508 - val_loss: 0.5507 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89800\n",
            "Epoch 64/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1393 - accuracy: 0.9504 - val_loss: 0.4353 - val_accuracy: 0.8946\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89800\n",
            "Epoch 65/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1373 - accuracy: 0.9529 - val_loss: 0.5047 - val_accuracy: 0.8950\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89800\n",
            "Epoch 66/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1384 - accuracy: 0.9511 - val_loss: 0.5120 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89800\n",
            "Epoch 67/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1343 - accuracy: 0.9531 - val_loss: 0.4893 - val_accuracy: 0.8939\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89800\n",
            "Epoch 68/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1393 - accuracy: 0.9514 - val_loss: 0.5189 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89800\n",
            "Epoch 69/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1372 - accuracy: 0.9525 - val_loss: 0.5037 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89800\n",
            "Epoch 70/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1372 - accuracy: 0.9534 - val_loss: 0.4834 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89800\n",
            "Epoch 71/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1317 - accuracy: 0.9549 - val_loss: 0.5750 - val_accuracy: 0.8866\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89800\n",
            "Epoch 72/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1330 - accuracy: 0.9538 - val_loss: 0.4345 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.89800\n",
            "Epoch 73/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1235 - accuracy: 0.9562 - val_loss: 0.5267 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.89800 to 0.89883, saving model to best-DR_BN.h5\n",
            "Epoch 74/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1245 - accuracy: 0.9566 - val_loss: 0.5321 - val_accuracy: 0.8950\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.89883\n",
            "Epoch 75/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1228 - accuracy: 0.9569 - val_loss: 0.5687 - val_accuracy: 0.8897\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.89883\n",
            "Epoch 76/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1284 - accuracy: 0.9573 - val_loss: 0.5584 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.89883\n",
            "Epoch 77/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1261 - accuracy: 0.9571 - val_loss: 0.5005 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.89883\n",
            "Epoch 78/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1277 - accuracy: 0.9556 - val_loss: 0.5391 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.89883\n",
            "Epoch 79/500\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1279 - accuracy: 0.9556 - val_loss: 0.5253 - val_accuracy: 0.8932\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.89883\n",
            "Epoch 80/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1270 - accuracy: 0.9561 - val_loss: 0.4785 - val_accuracy: 0.8974\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.89883\n",
            "Epoch 81/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1306 - accuracy: 0.9559 - val_loss: 0.5448 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.89883\n",
            "Epoch 82/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1202 - accuracy: 0.9578 - val_loss: 0.5812 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.89883\n",
            "Epoch 83/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1196 - accuracy: 0.9593 - val_loss: 0.5780 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.89883\n",
            "Epoch 84/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1249 - accuracy: 0.9557 - val_loss: 0.5208 - val_accuracy: 0.8931\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.89883\n",
            "Epoch 85/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1221 - accuracy: 0.9587 - val_loss: 0.4970 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.89883\n",
            "Epoch 86/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1167 - accuracy: 0.9598 - val_loss: 0.5543 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.89883\n",
            "Epoch 87/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1125 - accuracy: 0.9621 - val_loss: 0.5236 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.89883\n",
            "Epoch 88/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1175 - accuracy: 0.9599 - val_loss: 0.5426 - val_accuracy: 0.8946\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.89883\n",
            "Epoch 89/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1136 - accuracy: 0.9616 - val_loss: 0.5340 - val_accuracy: 0.8953\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.89883\n",
            "Epoch 90/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1201 - accuracy: 0.9602 - val_loss: 0.5051 - val_accuracy: 0.8933\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.89883\n",
            "Epoch 91/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1143 - accuracy: 0.9612 - val_loss: 0.5242 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.89883\n",
            "Epoch 92/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1199 - accuracy: 0.9605 - val_loss: 0.5901 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.89883\n",
            "Epoch 93/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1172 - accuracy: 0.9601 - val_loss: 0.5026 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.89883\n",
            "Epoch 94/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1210 - accuracy: 0.9604 - val_loss: 0.5639 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.89883\n",
            "Epoch 95/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1127 - accuracy: 0.9605 - val_loss: 0.5926 - val_accuracy: 0.8924\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.89883\n",
            "Epoch 96/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1123 - accuracy: 0.9613 - val_loss: 0.5087 - val_accuracy: 0.8888\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.89883\n",
            "Epoch 97/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1115 - accuracy: 0.9624 - val_loss: 0.5250 - val_accuracy: 0.8944\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.89883\n",
            "Epoch 98/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1084 - accuracy: 0.9632 - val_loss: 0.5867 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.89883\n",
            "Epoch 99/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1174 - accuracy: 0.9612 - val_loss: 0.5341 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.89883\n",
            "Epoch 100/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1109 - accuracy: 0.9624 - val_loss: 0.5196 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.89883\n",
            "Epoch 101/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1056 - accuracy: 0.9642 - val_loss: 0.6201 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.89883\n",
            "Epoch 102/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1036 - accuracy: 0.9642 - val_loss: 0.5755 - val_accuracy: 0.8961\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.89883\n",
            "Epoch 103/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1143 - accuracy: 0.9613 - val_loss: 0.6142 - val_accuracy: 0.8932\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.89883\n",
            "Epoch 104/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1136 - accuracy: 0.9627 - val_loss: 0.4977 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.89883\n",
            "Epoch 105/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1028 - accuracy: 0.9631 - val_loss: 0.5406 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.89883\n",
            "Epoch 106/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1085 - accuracy: 0.9641 - val_loss: 0.5492 - val_accuracy: 0.8992\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.89883 to 0.89917, saving model to best-DR_BN.h5\n",
            "Epoch 107/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1073 - accuracy: 0.9645 - val_loss: 0.6069 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.89917\n",
            "Epoch 108/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1060 - accuracy: 0.9625 - val_loss: 0.6064 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.89917\n",
            "Epoch 109/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1033 - accuracy: 0.9647 - val_loss: 0.5600 - val_accuracy: 0.8974\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.89917\n",
            "Epoch 110/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1037 - accuracy: 0.9640 - val_loss: 0.6512 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.89917\n",
            "Epoch 111/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1106 - accuracy: 0.9641 - val_loss: 0.5405 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.89917\n",
            "Epoch 112/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0996 - accuracy: 0.9663 - val_loss: 0.6255 - val_accuracy: 0.8989\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.89917\n",
            "Epoch 113/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0989 - accuracy: 0.9671 - val_loss: 0.5266 - val_accuracy: 0.8948\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.89917\n",
            "Epoch 114/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1041 - accuracy: 0.9664 - val_loss: 0.6431 - val_accuracy: 0.8903\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.89917\n",
            "Epoch 115/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0997 - accuracy: 0.9666 - val_loss: 0.5202 - val_accuracy: 0.8953\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.89917\n",
            "Epoch 116/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1034 - accuracy: 0.9659 - val_loss: 0.5673 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00116: val_accuracy improved from 0.89917 to 0.89958, saving model to best-DR_BN.h5\n",
            "Epoch 117/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0943 - accuracy: 0.9675 - val_loss: 0.6190 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.89958\n",
            "Epoch 118/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0956 - accuracy: 0.9686 - val_loss: 0.5557 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.89958\n",
            "Epoch 119/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1007 - accuracy: 0.9657 - val_loss: 0.6137 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.89958\n",
            "Epoch 120/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0948 - accuracy: 0.9696 - val_loss: 0.6701 - val_accuracy: 0.8940\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.89958\n",
            "Epoch 121/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0992 - accuracy: 0.9667 - val_loss: 0.5441 - val_accuracy: 0.8943\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.89958\n",
            "Epoch 122/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0967 - accuracy: 0.9690 - val_loss: 0.5969 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.89958\n",
            "Epoch 123/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0995 - accuracy: 0.9675 - val_loss: 0.6001 - val_accuracy: 0.8946\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.89958\n",
            "Epoch 124/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0978 - accuracy: 0.9670 - val_loss: 0.6218 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.89958\n",
            "Epoch 125/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0956 - accuracy: 0.9674 - val_loss: 0.5741 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.89958\n",
            "Epoch 126/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0925 - accuracy: 0.9681 - val_loss: 0.5905 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.89958\n",
            "Epoch 127/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0939 - accuracy: 0.9693 - val_loss: 0.5788 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.89958\n",
            "Epoch 128/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0986 - accuracy: 0.9692 - val_loss: 0.5764 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.89958\n",
            "Epoch 129/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0903 - accuracy: 0.9712 - val_loss: 0.7066 - val_accuracy: 0.8914\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.89958\n",
            "Epoch 130/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0917 - accuracy: 0.9686 - val_loss: 0.7430 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.89958\n",
            "Epoch 131/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0907 - accuracy: 0.9687 - val_loss: 0.7734 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.89958\n",
            "Epoch 132/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0927 - accuracy: 0.9693 - val_loss: 0.6670 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.89958\n",
            "Epoch 133/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0930 - accuracy: 0.9698 - val_loss: 0.5982 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.89958\n",
            "Epoch 134/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0904 - accuracy: 0.9705 - val_loss: 0.6319 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.89958\n",
            "Epoch 135/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0883 - accuracy: 0.9702 - val_loss: 0.6296 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.89958 to 0.90067, saving model to best-DR_BN.h5\n",
            "Epoch 136/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0886 - accuracy: 0.9701 - val_loss: 0.6230 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.90067\n",
            "Epoch 137/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0924 - accuracy: 0.9694 - val_loss: 0.6906 - val_accuracy: 0.8855\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.90067\n",
            "Epoch 138/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0890 - accuracy: 0.9695 - val_loss: 0.6490 - val_accuracy: 0.8998\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.90067\n",
            "Epoch 139/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0952 - accuracy: 0.9695 - val_loss: 0.6746 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.90067\n",
            "Epoch 140/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0879 - accuracy: 0.9705 - val_loss: 0.6673 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.90067\n",
            "Epoch 141/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0948 - accuracy: 0.9693 - val_loss: 0.5991 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.90067\n",
            "Epoch 142/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0911 - accuracy: 0.9714 - val_loss: 0.6088 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.90067\n",
            "Epoch 143/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0841 - accuracy: 0.9721 - val_loss: 0.7065 - val_accuracy: 0.8953\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.90067\n",
            "Epoch 144/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0851 - accuracy: 0.9721 - val_loss: 0.6655 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.90067\n",
            "Epoch 145/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0852 - accuracy: 0.9718 - val_loss: 0.7576 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.90067\n",
            "Epoch 146/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0895 - accuracy: 0.9702 - val_loss: 0.6625 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.90067\n",
            "Epoch 147/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0902 - accuracy: 0.9714 - val_loss: 0.6329 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.90067\n",
            "Epoch 148/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0837 - accuracy: 0.9716 - val_loss: 0.6811 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.90067\n",
            "Epoch 149/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0893 - accuracy: 0.9711 - val_loss: 0.6372 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.90067\n",
            "Epoch 150/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0880 - accuracy: 0.9706 - val_loss: 0.6617 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.90067\n",
            "Epoch 151/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0816 - accuracy: 0.9724 - val_loss: 0.6417 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.90067\n",
            "Epoch 152/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0859 - accuracy: 0.9714 - val_loss: 0.6675 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.90067\n",
            "Epoch 153/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0848 - accuracy: 0.9729 - val_loss: 0.6921 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.90067\n",
            "Epoch 154/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0825 - accuracy: 0.9734 - val_loss: 0.7201 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.90067\n",
            "Epoch 155/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0844 - accuracy: 0.9725 - val_loss: 0.6500 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.90067\n",
            "Epoch 156/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0876 - accuracy: 0.9715 - val_loss: 0.7027 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.90067\n",
            "Epoch 157/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0825 - accuracy: 0.9724 - val_loss: 0.6108 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.90067\n",
            "Epoch 158/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0875 - accuracy: 0.9717 - val_loss: 0.6871 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.90067\n",
            "Epoch 159/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0847 - accuracy: 0.9729 - val_loss: 0.6489 - val_accuracy: 0.8965\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.90067\n",
            "Epoch 160/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0772 - accuracy: 0.9746 - val_loss: 0.6397 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.90067\n",
            "Epoch 161/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0863 - accuracy: 0.9724 - val_loss: 0.6756 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.90067\n",
            "Epoch 162/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0813 - accuracy: 0.9730 - val_loss: 0.6254 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.90067\n",
            "Epoch 163/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0838 - accuracy: 0.9721 - val_loss: 0.7305 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.90067\n",
            "Epoch 164/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0886 - accuracy: 0.9713 - val_loss: 0.6094 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.90067\n",
            "Epoch 165/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0797 - accuracy: 0.9738 - val_loss: 0.7337 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.90067\n",
            "Epoch 166/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0856 - accuracy: 0.9727 - val_loss: 0.6490 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.90067\n",
            "Epoch 167/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0794 - accuracy: 0.9739 - val_loss: 0.6635 - val_accuracy: 0.8943\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.90067\n",
            "Epoch 168/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0833 - accuracy: 0.9748 - val_loss: 0.6785 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.90067\n",
            "Epoch 169/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0797 - accuracy: 0.9743 - val_loss: 0.6936 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.90067\n",
            "Epoch 170/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0749 - accuracy: 0.9761 - val_loss: 0.6714 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.90067\n",
            "Epoch 171/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0770 - accuracy: 0.9753 - val_loss: 0.8018 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.90067\n",
            "Epoch 172/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0770 - accuracy: 0.9755 - val_loss: 0.6907 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.90067\n",
            "Epoch 173/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0821 - accuracy: 0.9748 - val_loss: 0.6552 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.90067\n",
            "Epoch 174/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0834 - accuracy: 0.9744 - val_loss: 0.6791 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.90067\n",
            "Epoch 175/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0835 - accuracy: 0.9735 - val_loss: 0.6732 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.90067\n",
            "Epoch 176/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0727 - accuracy: 0.9758 - val_loss: 0.6467 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.90067\n",
            "Epoch 177/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0747 - accuracy: 0.9751 - val_loss: 0.7866 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.90067\n",
            "Epoch 178/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0770 - accuracy: 0.9754 - val_loss: 0.6638 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.90067\n",
            "Epoch 179/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0729 - accuracy: 0.9751 - val_loss: 0.7457 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.90067\n",
            "Epoch 180/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0779 - accuracy: 0.9752 - val_loss: 0.7516 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.90067\n",
            "Epoch 181/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0765 - accuracy: 0.9752 - val_loss: 0.6776 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.90067\n",
            "Epoch 182/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0766 - accuracy: 0.9772 - val_loss: 0.6867 - val_accuracy: 0.8989\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.90067\n",
            "Epoch 183/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0764 - accuracy: 0.9756 - val_loss: 0.7054 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.90067\n",
            "Epoch 184/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0743 - accuracy: 0.9762 - val_loss: 0.7373 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.90067\n",
            "Epoch 185/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0761 - accuracy: 0.9752 - val_loss: 0.6481 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 00185: val_accuracy improved from 0.90067 to 0.90075, saving model to best-DR_BN.h5\n",
            "Epoch 186/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0755 - accuracy: 0.9766 - val_loss: 0.7363 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.90075\n",
            "Epoch 187/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.6511 - val_accuracy: 0.8998\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.90075\n",
            "Epoch 188/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0738 - accuracy: 0.9766 - val_loss: 0.7484 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.90075\n",
            "Epoch 189/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0728 - accuracy: 0.9770 - val_loss: 0.7008 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.90075\n",
            "Epoch 190/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0707 - accuracy: 0.9784 - val_loss: 0.7215 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.90075\n",
            "Epoch 191/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0798 - accuracy: 0.9746 - val_loss: 0.7633 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.90075\n",
            "Epoch 192/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0742 - accuracy: 0.9767 - val_loss: 0.7221 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.90075\n",
            "Epoch 193/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0764 - accuracy: 0.9768 - val_loss: 0.7197 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.90075\n",
            "Epoch 194/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0696 - accuracy: 0.9759 - val_loss: 0.7421 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.90075\n",
            "Epoch 195/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0774 - accuracy: 0.9759 - val_loss: 0.6962 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.90075\n",
            "Epoch 196/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0764 - accuracy: 0.9768 - val_loss: 0.7288 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.90075\n",
            "Epoch 197/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0756 - accuracy: 0.9752 - val_loss: 0.7095 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.90075\n",
            "Epoch 198/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0733 - accuracy: 0.9764 - val_loss: 0.7105 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.90075\n",
            "Epoch 199/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0758 - accuracy: 0.9788 - val_loss: 0.7514 - val_accuracy: 0.8935\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.90075\n",
            "Epoch 200/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0683 - accuracy: 0.9778 - val_loss: 0.7443 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.90075\n",
            "Epoch 201/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0745 - accuracy: 0.9762 - val_loss: 0.6697 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.90075\n",
            "Epoch 202/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0713 - accuracy: 0.9770 - val_loss: 0.7175 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.90075\n",
            "Epoch 203/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0734 - accuracy: 0.9765 - val_loss: 0.6266 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.90075\n",
            "Epoch 204/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0718 - accuracy: 0.9775 - val_loss: 0.7177 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.90075\n",
            "Epoch 205/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0717 - accuracy: 0.9765 - val_loss: 0.7701 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.90075\n",
            "Epoch 206/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0689 - accuracy: 0.9782 - val_loss: 0.7164 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.90075\n",
            "Epoch 207/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0728 - accuracy: 0.9773 - val_loss: 0.7165 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.90075\n",
            "Epoch 208/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0684 - accuracy: 0.9786 - val_loss: 0.7645 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.90075\n",
            "Epoch 209/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0739 - accuracy: 0.9773 - val_loss: 0.7748 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.90075\n",
            "Epoch 210/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0720 - accuracy: 0.9772 - val_loss: 0.7505 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.90075\n",
            "Epoch 211/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0663 - accuracy: 0.9792 - val_loss: 0.7132 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.90075\n",
            "Epoch 212/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.7426 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.90075\n",
            "Epoch 213/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0687 - accuracy: 0.9780 - val_loss: 0.7059 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.90075\n",
            "Epoch 214/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0700 - accuracy: 0.9781 - val_loss: 0.7874 - val_accuracy: 0.8993\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.90075\n",
            "Epoch 215/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0727 - accuracy: 0.9789 - val_loss: 0.6773 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.90075\n",
            "Epoch 216/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0687 - accuracy: 0.9787 - val_loss: 0.8160 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.90075\n",
            "Epoch 217/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0720 - accuracy: 0.9797 - val_loss: 0.7533 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.90075\n",
            "Epoch 218/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0665 - accuracy: 0.9790 - val_loss: 0.8640 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.90075\n",
            "Epoch 219/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.7355 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.90075\n",
            "Epoch 220/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0692 - accuracy: 0.9790 - val_loss: 0.7436 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.90075\n",
            "Epoch 221/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0660 - accuracy: 0.9781 - val_loss: 0.8399 - val_accuracy: 0.8980\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.90075\n",
            "Epoch 222/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0662 - accuracy: 0.9796 - val_loss: 0.7611 - val_accuracy: 0.8943\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.90075\n",
            "Epoch 223/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 0.7967 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.90075\n",
            "Epoch 224/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9795 - val_loss: 0.7644 - val_accuracy: 0.8950\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.90075\n",
            "Epoch 225/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0658 - accuracy: 0.9789 - val_loss: 0.7675 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.90075\n",
            "Epoch 226/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0655 - accuracy: 0.9796 - val_loss: 0.7868 - val_accuracy: 0.8935\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.90075\n",
            "Epoch 227/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0684 - accuracy: 0.9783 - val_loss: 0.7955 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.90075\n",
            "Epoch 228/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0682 - accuracy: 0.9788 - val_loss: 0.7031 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.90075\n",
            "Epoch 229/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0711 - accuracy: 0.9783 - val_loss: 0.7256 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.90075\n",
            "Epoch 230/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0727 - accuracy: 0.9785 - val_loss: 0.7731 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.90075\n",
            "Epoch 231/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0657 - accuracy: 0.9799 - val_loss: 0.7755 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.90075\n",
            "Epoch 232/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0650 - accuracy: 0.9790 - val_loss: 0.8567 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.90075\n",
            "Epoch 233/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 0.7691 - val_accuracy: 0.8931\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.90075\n",
            "Epoch 234/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.7724 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.90075\n",
            "Epoch 235/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0626 - accuracy: 0.9804 - val_loss: 0.8090 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.90075\n",
            "Epoch 236/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0630 - accuracy: 0.9799 - val_loss: 0.7954 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.90075\n",
            "Epoch 237/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9786 - val_loss: 0.7718 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.90075\n",
            "Epoch 238/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0635 - accuracy: 0.9811 - val_loss: 0.7792 - val_accuracy: 0.8992\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.90075\n",
            "Epoch 239/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0657 - accuracy: 0.9796 - val_loss: 0.7819 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.90075\n",
            "Epoch 240/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0680 - accuracy: 0.9800 - val_loss: 0.7878 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.90075\n",
            "Epoch 241/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0640 - accuracy: 0.9808 - val_loss: 0.7993 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.90075\n",
            "Epoch 242/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0644 - accuracy: 0.9811 - val_loss: 0.8140 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.90075\n",
            "Epoch 243/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.7651 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.90075\n",
            "Epoch 244/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0641 - accuracy: 0.9802 - val_loss: 0.8460 - val_accuracy: 0.8961\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.90075\n",
            "Epoch 245/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.7995 - val_accuracy: 0.8976\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.90075\n",
            "Epoch 246/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.8522 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.90075\n",
            "Epoch 247/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 0.7850 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.90075\n",
            "Epoch 248/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.8035 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.90075\n",
            "Epoch 249/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9792 - val_loss: 0.8055 - val_accuracy: 0.8980\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.90075\n",
            "Epoch 250/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0632 - accuracy: 0.9815 - val_loss: 0.7750 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.90075\n",
            "Epoch 251/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.7667 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.90075\n",
            "Epoch 252/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.7607 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.90075\n",
            "Epoch 253/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9809 - val_loss: 0.7571 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.90075\n",
            "Epoch 254/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0602 - accuracy: 0.9815 - val_loss: 0.7968 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.90075\n",
            "Epoch 255/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0625 - accuracy: 0.9812 - val_loss: 0.7800 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.90075\n",
            "Epoch 256/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.7480 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.90075\n",
            "Epoch 257/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0604 - accuracy: 0.9818 - val_loss: 0.8223 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.90075\n",
            "Epoch 258/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0616 - accuracy: 0.9814 - val_loss: 0.7758 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.90075\n",
            "Epoch 259/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0575 - accuracy: 0.9817 - val_loss: 0.7815 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.90075\n",
            "Epoch 260/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0619 - accuracy: 0.9827 - val_loss: 0.8243 - val_accuracy: 0.8940\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.90075\n",
            "Epoch 261/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0603 - accuracy: 0.9813 - val_loss: 0.7447 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.90075\n",
            "Epoch 262/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0620 - accuracy: 0.9806 - val_loss: 0.8438 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.90075\n",
            "Epoch 263/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0625 - accuracy: 0.9809 - val_loss: 0.8323 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.90075\n",
            "Epoch 264/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0588 - accuracy: 0.9820 - val_loss: 0.7748 - val_accuracy: 0.8989\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.90075\n",
            "Epoch 265/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0616 - accuracy: 0.9817 - val_loss: 0.7589 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.90075\n",
            "Epoch 266/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0590 - accuracy: 0.9814 - val_loss: 0.8601 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.90075\n",
            "Epoch 267/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.8257 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.90075\n",
            "Epoch 268/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.6984 - val_accuracy: 0.8965\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.90075\n",
            "Epoch 269/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0619 - accuracy: 0.9815 - val_loss: 0.8494 - val_accuracy: 0.8927\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.90075\n",
            "Epoch 270/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0630 - accuracy: 0.9812 - val_loss: 0.8037 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.90075\n",
            "Epoch 271/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.7999 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.90075\n",
            "Epoch 272/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0596 - accuracy: 0.9821 - val_loss: 0.8117 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.90075\n",
            "Epoch 273/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0576 - accuracy: 0.9819 - val_loss: 0.7558 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.90075\n",
            "Epoch 274/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0605 - accuracy: 0.9822 - val_loss: 0.7828 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.90075\n",
            "Epoch 275/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0618 - accuracy: 0.9821 - val_loss: 0.8102 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.90075\n",
            "Epoch 276/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 0.8281 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.90075\n",
            "Epoch 277/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.8062 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.90075\n",
            "Epoch 278/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0580 - accuracy: 0.9830 - val_loss: 0.7450 - val_accuracy: 0.8980\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.90075\n",
            "Epoch 279/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0627 - accuracy: 0.9808 - val_loss: 0.7786 - val_accuracy: 0.9008\n",
            "\n",
            "Epoch 00279: val_accuracy improved from 0.90075 to 0.90083, saving model to best-DR_BN.h5\n",
            "Epoch 280/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.7922 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.90083\n",
            "Epoch 281/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.8846 - val_accuracy: 0.8935\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.90083\n",
            "Epoch 282/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.8110 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.90083\n",
            "Epoch 283/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 0.8278 - val_accuracy: 0.8961\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.90083\n",
            "Epoch 284/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.7998 - val_accuracy: 0.8952\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.90083\n",
            "Epoch 285/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0586 - accuracy: 0.9827 - val_loss: 0.8185 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.90083\n",
            "Epoch 286/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0557 - accuracy: 0.9836 - val_loss: 0.8199 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.90083\n",
            "Epoch 287/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.8529 - val_accuracy: 0.8946\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.90083\n",
            "Epoch 288/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0616 - accuracy: 0.9819 - val_loss: 0.8333 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.90083\n",
            "Epoch 289/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0581 - accuracy: 0.9834 - val_loss: 0.8188 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.90083\n",
            "Epoch 290/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: 0.8045 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.90083\n",
            "Epoch 291/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0599 - accuracy: 0.9814 - val_loss: 0.7640 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.90083\n",
            "Epoch 292/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.8395 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.90083\n",
            "Epoch 293/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0529 - accuracy: 0.9825 - val_loss: 0.7989 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.90083\n",
            "Epoch 294/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0620 - accuracy: 0.9817 - val_loss: 0.7280 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.90083\n",
            "Epoch 295/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0582 - accuracy: 0.9828 - val_loss: 0.7856 - val_accuracy: 0.8976\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.90083\n",
            "Epoch 296/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0483 - accuracy: 0.9845 - val_loss: 0.7742 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.90083\n",
            "Epoch 297/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0551 - accuracy: 0.9840 - val_loss: 0.8089 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.90083\n",
            "Epoch 298/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0586 - accuracy: 0.9839 - val_loss: 0.8222 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.90083\n",
            "Epoch 299/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0614 - accuracy: 0.9829 - val_loss: 0.8430 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.90083\n",
            "Epoch 300/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 0.8817 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.90083\n",
            "Epoch 301/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0559 - accuracy: 0.9843 - val_loss: 0.7997 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.90083\n",
            "Epoch 302/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.8288 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.90083\n",
            "Epoch 303/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0542 - accuracy: 0.9846 - val_loss: 0.8294 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.90083\n",
            "Epoch 304/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.7981 - val_accuracy: 0.8933\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.90083\n",
            "Epoch 305/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0566 - accuracy: 0.9814 - val_loss: 0.8598 - val_accuracy: 0.8927\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.90083\n",
            "Epoch 306/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0593 - accuracy: 0.9828 - val_loss: 0.8493 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.90083\n",
            "Epoch 307/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0563 - accuracy: 0.9829 - val_loss: 0.7613 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.90083\n",
            "Epoch 308/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0572 - accuracy: 0.9833 - val_loss: 0.7809 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.90083\n",
            "Epoch 309/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0563 - accuracy: 0.9832 - val_loss: 0.8004 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.90083\n",
            "Epoch 310/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0537 - accuracy: 0.9842 - val_loss: 0.9079 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.90083\n",
            "Epoch 311/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0536 - accuracy: 0.9829 - val_loss: 0.8846 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.90083\n",
            "Epoch 312/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0530 - accuracy: 0.9841 - val_loss: 0.8020 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.90083\n",
            "Epoch 313/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.8196 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.90083\n",
            "Epoch 314/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0573 - accuracy: 0.9833 - val_loss: 0.7888 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.90083\n",
            "Epoch 315/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0598 - accuracy: 0.9826 - val_loss: 0.7851 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.90083\n",
            "Epoch 316/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0593 - accuracy: 0.9831 - val_loss: 0.7954 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.90083\n",
            "Epoch 317/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0581 - accuracy: 0.9829 - val_loss: 0.8018 - val_accuracy: 0.8950\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.90083\n",
            "Epoch 318/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0515 - accuracy: 0.9851 - val_loss: 0.8767 - val_accuracy: 0.8976\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.90083\n",
            "Epoch 319/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0553 - accuracy: 0.9841 - val_loss: 0.8756 - val_accuracy: 0.8987\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.90083\n",
            "Epoch 320/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0573 - accuracy: 0.9836 - val_loss: 0.9033 - val_accuracy: 0.8974\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.90083\n",
            "Epoch 321/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0538 - accuracy: 0.9839 - val_loss: 0.8720 - val_accuracy: 0.8951\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.90083\n",
            "Epoch 322/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0525 - accuracy: 0.9839 - val_loss: 0.8607 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.90083\n",
            "Epoch 323/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9839 - val_loss: 0.7841 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.90083\n",
            "Epoch 324/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0561 - accuracy: 0.9839 - val_loss: 0.8074 - val_accuracy: 0.8975\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.90083\n",
            "Epoch 325/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9839 - val_loss: 0.7781 - val_accuracy: 0.9013\n",
            "\n",
            "Epoch 00325: val_accuracy improved from 0.90083 to 0.90133, saving model to best-DR_BN.h5\n",
            "Epoch 326/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9836 - val_loss: 0.8995 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.90133\n",
            "Epoch 327/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0559 - accuracy: 0.9834 - val_loss: 0.8373 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.90133\n",
            "Epoch 328/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.8671 - val_accuracy: 0.8975\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.90133\n",
            "Epoch 329/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0544 - accuracy: 0.9841 - val_loss: 0.7952 - val_accuracy: 0.9001\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.90133\n",
            "Epoch 330/500\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0560 - accuracy: 0.9839 - val_loss: 0.8761 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.90133\n",
            "Epoch 331/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0554 - accuracy: 0.9844 - val_loss: 0.8158 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.90133\n",
            "Epoch 332/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0539 - accuracy: 0.9853 - val_loss: 0.8054 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.90133\n",
            "Epoch 333/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0518 - accuracy: 0.9848 - val_loss: 0.9224 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.90133\n",
            "Epoch 334/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0552 - accuracy: 0.9835 - val_loss: 0.8393 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.90133\n",
            "Epoch 335/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 0.8087 - val_accuracy: 0.8961\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.90133\n",
            "Epoch 336/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.7772 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.90133\n",
            "Epoch 337/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.8213 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.90133\n",
            "Epoch 338/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0506 - accuracy: 0.9848 - val_loss: 0.8509 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.90133\n",
            "Epoch 339/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0517 - accuracy: 0.9843 - val_loss: 0.9294 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.90133\n",
            "Epoch 340/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.8240 - val_accuracy: 0.8949\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.90133\n",
            "Epoch 341/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0576 - accuracy: 0.9842 - val_loss: 0.8761 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.90133\n",
            "Epoch 342/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0540 - accuracy: 0.9841 - val_loss: 0.8783 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.90133\n",
            "Epoch 343/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0523 - accuracy: 0.9845 - val_loss: 0.9031 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.90133\n",
            "Epoch 344/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0538 - accuracy: 0.9840 - val_loss: 0.9491 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.90133\n",
            "Epoch 345/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 0.8647 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.90133\n",
            "Epoch 346/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.8623 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.90133\n",
            "Epoch 347/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0539 - accuracy: 0.9840 - val_loss: 0.8734 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.90133\n",
            "Epoch 348/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0563 - accuracy: 0.9845 - val_loss: 0.8423 - val_accuracy: 0.9011\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.90133\n",
            "Epoch 349/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.9224 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.90133\n",
            "Epoch 350/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0509 - accuracy: 0.9848 - val_loss: 0.7816 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.90133\n",
            "Epoch 351/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0523 - accuracy: 0.9845 - val_loss: 0.9160 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.90133\n",
            "Epoch 352/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 0.8316 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.90133\n",
            "Epoch 353/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0466 - accuracy: 0.9858 - val_loss: 0.8948 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.90133\n",
            "Epoch 354/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0504 - accuracy: 0.9853 - val_loss: 0.8550 - val_accuracy: 0.8943\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.90133\n",
            "Epoch 355/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0511 - accuracy: 0.9851 - val_loss: 0.9175 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.90133\n",
            "Epoch 356/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0520 - accuracy: 0.9843 - val_loss: 0.8510 - val_accuracy: 0.8993\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.90133\n",
            "Epoch 357/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0510 - accuracy: 0.9855 - val_loss: 0.8263 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.90133\n",
            "Epoch 358/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0493 - accuracy: 0.9861 - val_loss: 0.8943 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.90133\n",
            "Epoch 359/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 0.8554 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.90133\n",
            "Epoch 360/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.8073 - val_accuracy: 0.8950\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.90133\n",
            "Epoch 361/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0527 - accuracy: 0.9851 - val_loss: 0.9350 - val_accuracy: 0.8970\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.90133\n",
            "Epoch 362/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0483 - accuracy: 0.9858 - val_loss: 0.8917 - val_accuracy: 0.8976\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.90133\n",
            "Epoch 363/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 0.8887 - val_accuracy: 0.9012\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.90133\n",
            "Epoch 364/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0468 - accuracy: 0.9867 - val_loss: 0.9065 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.90133\n",
            "Epoch 365/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0499 - accuracy: 0.9861 - val_loss: 0.8758 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.90133\n",
            "Epoch 366/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0493 - accuracy: 0.9856 - val_loss: 0.8748 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.90133\n",
            "Epoch 367/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0501 - accuracy: 0.9850 - val_loss: 0.9192 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.90133\n",
            "Epoch 368/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0526 - accuracy: 0.9838 - val_loss: 0.8219 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.90133\n",
            "Epoch 369/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.9109 - val_accuracy: 0.8937\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.90133\n",
            "Epoch 370/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0525 - accuracy: 0.9848 - val_loss: 0.8332 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.90133\n",
            "Epoch 371/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.8874 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.90133\n",
            "Epoch 372/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.8055 - val_accuracy: 0.8999\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.90133\n",
            "Epoch 373/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0485 - accuracy: 0.9852 - val_loss: 0.8913 - val_accuracy: 0.8992\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.90133\n",
            "Epoch 374/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0535 - accuracy: 0.9853 - val_loss: 0.8677 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.90133\n",
            "Epoch 375/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 0.7784 - val_accuracy: 0.8965\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.90133\n",
            "Epoch 376/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0483 - accuracy: 0.9861 - val_loss: 0.8613 - val_accuracy: 0.8980\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.90133\n",
            "Epoch 377/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0476 - accuracy: 0.9867 - val_loss: 0.8868 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.90133\n",
            "Epoch 378/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0488 - accuracy: 0.9856 - val_loss: 0.8598 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.90133\n",
            "Epoch 379/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0502 - accuracy: 0.9851 - val_loss: 0.8847 - val_accuracy: 0.8976\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.90133\n",
            "Epoch 380/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.8882 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.90133\n",
            "Epoch 381/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.9297 - val_accuracy: 0.8970\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.90133\n",
            "Epoch 382/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0479 - accuracy: 0.9859 - val_loss: 0.8662 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.90133\n",
            "Epoch 383/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.8498 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.90133\n",
            "Epoch 384/500\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0464 - accuracy: 0.9867 - val_loss: 0.8257 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.90133\n",
            "Epoch 385/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0505 - accuracy: 0.9861 - val_loss: 0.8360 - val_accuracy: 0.8992\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.90133\n",
            "Epoch 386/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.8591 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.90133\n",
            "Epoch 387/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0489 - accuracy: 0.9867 - val_loss: 0.9070 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.90133\n",
            "Epoch 388/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0465 - accuracy: 0.9864 - val_loss: 0.7952 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.90133\n",
            "Epoch 389/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0529 - accuracy: 0.9850 - val_loss: 0.8220 - val_accuracy: 0.9004\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.90133\n",
            "Epoch 390/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0487 - accuracy: 0.9859 - val_loss: 0.9120 - val_accuracy: 0.8965\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.90133\n",
            "Epoch 391/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.9222 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.90133\n",
            "Epoch 392/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 0.8736 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.90133\n",
            "Epoch 393/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0479 - accuracy: 0.9868 - val_loss: 0.8842 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.90133\n",
            "Epoch 394/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.8735 - val_accuracy: 0.8975\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.90133\n",
            "Epoch 395/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0446 - accuracy: 0.9871 - val_loss: 0.8844 - val_accuracy: 0.9002\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.90133\n",
            "Epoch 396/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.8757 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.90133\n",
            "Epoch 397/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 0.8446 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.90133\n",
            "Epoch 398/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0411 - accuracy: 0.9876 - val_loss: 0.8355 - val_accuracy: 0.9011\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.90133\n",
            "Epoch 399/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0525 - accuracy: 0.9849 - val_loss: 0.9153 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.90133\n",
            "Epoch 400/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 0.8484 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.90133\n",
            "Epoch 401/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0466 - accuracy: 0.9870 - val_loss: 0.8949 - val_accuracy: 0.8999\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.90133\n",
            "Epoch 402/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0469 - accuracy: 0.9867 - val_loss: 0.9031 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.90133\n",
            "Epoch 403/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.8611 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.90133\n",
            "Epoch 404/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 0.9285 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.90133\n",
            "Epoch 405/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0475 - accuracy: 0.9869 - val_loss: 0.7934 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.90133\n",
            "Epoch 406/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0479 - accuracy: 0.9854 - val_loss: 0.8799 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.90133\n",
            "Epoch 407/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0474 - accuracy: 0.9860 - val_loss: 0.8930 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.90133\n",
            "Epoch 408/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0449 - accuracy: 0.9868 - val_loss: 0.8050 - val_accuracy: 0.9009\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.90133\n",
            "Epoch 409/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0468 - accuracy: 0.9880 - val_loss: 0.8731 - val_accuracy: 0.8948\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.90133\n",
            "Epoch 410/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0474 - accuracy: 0.9863 - val_loss: 0.9224 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.90133\n",
            "Epoch 411/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.8820 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.90133\n",
            "Epoch 412/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0428 - accuracy: 0.9871 - val_loss: 0.8826 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.90133\n",
            "Epoch 413/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.9127 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.90133\n",
            "Epoch 414/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 0.9523 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.90133\n",
            "Epoch 415/500\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.8594 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.90133\n",
            "Epoch 416/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0451 - accuracy: 0.9870 - val_loss: 0.9793 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.90133\n",
            "Epoch 417/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0501 - accuracy: 0.9868 - val_loss: 0.8919 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.90133\n",
            "Epoch 418/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0435 - accuracy: 0.9874 - val_loss: 0.8634 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.90133\n",
            "Epoch 419/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.8441 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.90133\n",
            "Epoch 420/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0451 - accuracy: 0.9867 - val_loss: 0.8952 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.90133\n",
            "Epoch 421/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0488 - accuracy: 0.9857 - val_loss: 0.8695 - val_accuracy: 0.8973\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.90133\n",
            "Epoch 422/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.9060 - val_accuracy: 0.8997\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.90133\n",
            "Epoch 423/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0443 - accuracy: 0.9876 - val_loss: 0.8319 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.90133\n",
            "Epoch 424/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.9214 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.90133\n",
            "Epoch 425/500\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0451 - accuracy: 0.9869 - val_loss: 0.9096 - val_accuracy: 0.8998\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.90133\n",
            "Epoch 00425: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCkWn3kU_D8P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "9d861300-f5b7-4df7-d16d-f9e8b687017e"
      },
      "source": [
        "\n",
        "epochs = range(1, len(Hist_DR_BN.history['loss'])+1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, Hist_DR_BN.history['loss'])\n",
        "plt.plot(epochs, Hist_DR_BN.history['val_loss'])\n",
        "plt.legend(['Train loss','Test loss'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, Hist_DR_BN.history['accuracy'])\n",
        "plt.plot(epochs, Hist_DR_BN.history['val_accuracy'])\n",
        "plt.legend(['accuracy','val_accuracy'])\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQz6UWU0_D8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f07f2e-2a66-4f2b-d8b8-e62d30123d87"
      },
      "source": [
        "loss_DR_BN, accuracy_DR_BN = DR_BN.evaluate(X_test, y_test)\n",
        "print('Loss = {:.5f}'.format(loss_DR_BN))\n",
        "print('Accuracy = {:.5f}'.format (accuracy_DR_BN))\n",
        "\n",
        "# accuracy 90찍을 뻔 했는데.. epoch(학습량)를 늘려야 했나?? 아님, "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9164 - accuracy: 0.8959\n",
            "Loss = 0.91640\n",
            "Accuracy = 0.89590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIo0PLU2Yz8x"
      },
      "source": [
        "# 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp0bWKaQYzti",
        "outputId": "b48c5b35-ab40-47f0-f129-10a9ef9f35d2"
      },
      "source": [
        "print('L2 Loss = {:.5f}, L2 Accuracy = {:.5f}'.format(loss_L2, accuracy_L2))\n",
        "print('L2 + BatchNormal Loss = {:.5f}, L2 + BatchNormal Accuracy = {:.5f}'.format(loss_L2_BN, accuracy_L2_BN ))\n",
        "print('Dropout + BatchNormal Loss = {:.5f}, Dropout + BatchNormal Accuracy = {:.5f}'.format(loss_DR_BN, accuracy_DR_BN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 Loss = 0.99603, L2 Accuracy = 0.88630\n",
            "L2 + BatchNormal Loss = 1.14954, L2 + BatchNormal Accuracy = 0.87810\n",
            "Dropout + BatchNormal Loss = 0.91640, Dropout + BatchNormal Accuracy = 0.89590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63BhK1ZsiyM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVVK0TpEsjFr"
      },
      "source": [
        "df_result = pd.DataFrame({\n",
        "                          \"Model\" : ['Default', 'BN', 'BN + Dropout'],\n",
        "                          \"Accuracy\" : [accuracy1, accuracy2, accuracy3],\n",
        "                          \"Val_Loss\" : [loss1, loss2, loss3]})\n",
        "                          \n",
        "df_result.sort_values(by=['Accuracy'], axis=0, ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}